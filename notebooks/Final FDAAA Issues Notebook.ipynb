{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from dateutil.relativedelta import relativedelta \n",
    "from tqdm.auto import tqdm\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "from zipfile import ZipFile\n",
    " \n",
    "from time import time\n",
    "from time import sleep\n",
    "from io import StringIO\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "cwd = os.getcwd()\n",
    "parent = str(Path(cwd).parents[0])\n",
    "sys.path.append(parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Managing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If the main data file exists, it will read it, if not it will create it from the raw data.\n",
    "#See files in lib folder and function docstrings for details of functions.\n",
    "#For the full analysis, We've run this process twice, once for all trials and once just for \n",
    "#applicable trials\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(parent + '/data/applicable_trials_2020-01-17.csv')    \n",
    "except FileNotFoundError:\n",
    "    old_fda = parent + '/data/fdaaa_regulatory_snapshot.csv'\n",
    "    \n",
    "    #This data is the full ClinicalTrials.gov dataset for 17 Jan 2020.\n",
    "    #Due to size, this is not in our GitHub repo, but stored separately on Figshare \n",
    "    #If you want to run this from scratch, unzip to the CSV and make sure the existing processed\n",
    "    #data file is deleted or renamed.\n",
    "    path = parent + '/data/raw_data/clinicaltrials_raw_clincialtrials_json_2020-01-17.csv'\n",
    "\n",
    "    from lib.data_functions import fda_reg, get_data\n",
    "\n",
    "    fda_reg_dict = fda_reg(old_fda)\n",
    "    lines = get_data(path)\n",
    "\n",
    "    #header names needed to create the dataset\n",
    "    headers = ['nct_id', 'act_flag', 'included_pact_flag', 'results_due', 'has_results','pending_results', 'pending_data',\n",
    "               'has_certificate', 'late_cert', 'certificate_date', \"certificate_date_qc\", \"certificate_posted_date\",\n",
    "               'primary_completion_date', 'completion_date', 'available_completion_date', 'due_date', 'last_updated_date', \n",
    "               'last_verified_date', 'results_first_submitted_date', 'results_submitted_date_qc', 'results_first_posted_date', \n",
    "               'first_results_submission_any', 'study_first_submitted_date', 'study_submitted_date_qc', \n",
    "               'study_first_posted_date', 'documents', 'sponsor', 'sponsor_type', 'phase', 'location', 'study_status', \n",
    "               'study_type', 'primary_purpose', 'fda_reg_drug', 'fda_reg_device', 'is_fda_regulated', 'discrep_date_status', \n",
    "               'defaulted_date', 'collaborators','start_date', 'used_primary_completion_date', 'defaulted_pcd_flag', \n",
    "               'defaulted_cd_flag', 'intervention_types']\n",
    "\n",
    "    from lib.final_df import make_row, make_dataframe\n",
    "\n",
    "    df = make_dataframe(tqdm(lines), fda_reg_dict, headers, act_filter=True, scrape_date = date(2020,1,17))\n",
    "\n",
    "    #Rename and uncomment this to save as a csv as appropriate\n",
    "    #df.to_csv('applicable_trials_2020-01-17.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(223.0, 908.0], (12.0, 223.0], (908.0, 3297.0], (0.999, 12.0]]\n",
      "Categories (4, interval[float64]): [(0.999, 12.0] < (12.0, 223.0] < (223.0, 908.0] < (908.0, 3297.0]]\n"
     ]
    }
   ],
   "source": [
    "#creating the sponsor size variable for regressions\n",
    "\n",
    "#This file is zipped for easier storage on GitHub\n",
    "zip_file = ZipFile(parent + '/data/all_trials_2020-01-17.csv.zip')\n",
    "\n",
    "#Load from zipped file\n",
    "all_trials = pd.read_csv(zip_file.open('all_trials_2020-01-17.csv'))\n",
    "del zip_file\n",
    "\n",
    "#Getting counts of each sponsor across all of ClinicalTrials.gov\n",
    "#Making a single column and dummies\n",
    "group = all_trials[['nct_id', 'sponsor']].groupby('sponsor', as_index = False).count()\n",
    "group.columns = ['sponsor', 'sponsored_trials']\n",
    "df = df.merge(group, how='left', on='sponsor')\n",
    "df['sponsor_quartile'] = pd.Categorical(pd.qcut(df.sponsored_trials, 4, labels=False), ordered=True)\n",
    "s_q_df = pd.get_dummies(df.sponsor_quartile, prefix='s_q')\n",
    "df = df.join(s_q_df)\n",
    "\n",
    "#renaming columns\n",
    "quart_rename = {'s_q_0': 'quartile_1', 's_q_1': 'quartile_2',  \n",
    "                's_q_2': 'quartile_3', 's_q_3': 'quartile_4'}\n",
    "df.rename(columns=quart_rename, inplace=True)\n",
    "\n",
    "#Checking the ranges\n",
    "quartile_ranges = pd.qcut(df.sponsored_trials, 4)\n",
    "print(quartile_ranges.unique())\n",
    "\n",
    "#creating a count of sponsors for applicable trials for rankings\n",
    "app_group = df[['nct_id', 'sponsor']].groupby('sponsor', as_index = False).count()\n",
    "app_group.columns = ['sponsor', 'covered_trials']\n",
    "df = df.merge(app_group, how='left', on='sponsor')\n",
    "#This is grouped by mean because each \"group\" of a single sponsor contains the same number of trials\n",
    "#Could easily just be .max() or .min() as well\n",
    "covered_trials = df[['sponsor', 'covered_trials']].groupby(by='sponsor', as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1, 3, 0]\n",
       "Categories (4, int64): [0 < 1 < 2 < 3]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check that the quartiles assigned correctly\n",
    "df['sponsor_quartile'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating regression variables for use throughout\n",
    "df['ind_spon'] = np.where(df.sponsor_type == 'Industry', 1, 0)\n",
    "df['drug_trial'] = np.where(df.intervention_types.str.contains('Drug'), 1, 0)\n",
    "phase_cats = ['Phase 1/Phase 2', 'Phase 2', 'Phase 2/Phase 3', 'Phase 3', 'Phase 4', 'N/A']\n",
    "df.phase.fillna('N/A', inplace=True)\n",
    "df['phase_collapsed'] = np.where(df.phase.isin(phase_cats[0:2]), 'Early Phase', \n",
    "                                np.where(df.phase.isin(phase_cats[2:4]), 'Late Phase', \"N/A\"))\n",
    "df['phase_var'] = pd.Categorical(df.phase_collapsed, ordered=True, \n",
    "                                 categories = ['Early Phase', 'Late Phase', 'N/A'])\n",
    "df['phase_var'] = df['phase_var'].cat.codes.astype('category')\n",
    "phase_df = pd.get_dummies(df.phase_var, prefix = 'phase_cat')\n",
    "\n",
    "df = df.join(phase_df)\n",
    "\n",
    "phase_rename = {'phase_cat_0': 'early_phase', 'phase_cat_1': 'late_phase', 'phase_cat_2': 'N/A'}\n",
    "\n",
    "df.rename(columns=phase_rename, inplace=True)\n",
    "\n",
    "#Making sure date columns are dates\n",
    "date_cols = ['certificate_date', \"certificate_date_qc\", \"certificate_posted_date\", 'primary_completion_date', 'completion_date', \n",
    "             'available_completion_date', 'due_date', 'last_updated_date', 'last_verified_date', 'results_first_submitted_date', \n",
    "             'results_submitted_date_qc', 'results_first_posted_date',  'first_results_submission_any', \n",
    "             'study_first_submitted_date', 'study_submitted_date_qc', 'study_first_posted_date', 'start_date']\n",
    "\n",
    "for col in date_cols:\n",
    "    df[col] = pd.to_datetime(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing functions created for analysis\n",
    "from lib.analysis_functions import crosstab, simple_logistic_regression, create_ranking, get_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall Cohort Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of 17 January 2020, there are 327154 trials and\n",
      "22902 publicly identifiable applicable trials covered by the law.\n",
      "13613 (59.4%) of these are identifiable as ACTs \n",
      "and 9289 (40.6%) as pACTs.\n",
      "5320 (23.2%) are due to report results.\n",
      "3825 (16.7%) of the entire cohort \n",
      "and 3409 (64.1%) of the due cohort have any results submitted.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "#Describing full data\n",
    "total = len(all_trials)\n",
    "all_applicable = len(df)\n",
    "acts = df.act_flag.sum()\n",
    "pacts = df.included_pact_flag.sum()\n",
    "results_due = df.results_due.sum()\n",
    "due_reported = len(df[(((df.has_results == 1) | (df.pending_results == 1)) & (df.results_due == 1))])\n",
    "results_all = df.has_results.sum() + df.pending_results.sum()\n",
    "\n",
    "print(\n",
    "    f'''As of 17 January 2020, there are {total} trials and\n",
    "{all_applicable} publicly identifiable applicable trials covered by the law.\n",
    "{acts} ({round(acts/all_applicable * 100,1)}%) of these are identifiable as ACTs \n",
    "and {pacts} ({round(pacts/all_applicable * 100,1)}%) as pACTs.\n",
    "{results_due} ({round(results_due/all_applicable * 100 ,1)}%) are due to report results.\n",
    "{results_all} ({round(results_all/all_applicable * 100 ,1)}%) of the entire cohort \n",
    "and {due_reported} ({round(due_reported/results_due * 100 ,1)}%) of the due cohort have any results submitted.\n",
    "    '''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use this function to get the counts of values for any variable in the dataset\n",
    "#Can use this on any study population throughout the analysis\n",
    "\n",
    "#Example\n",
    "get_count(df, 'sponsor_quartile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Registration - Prospective and >21 Days Late"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the fields we need\n",
    "pr_cats = ['nct_id', 'act_flag', 'included_pact_flag', 'start_date', 'study_first_submitted_date', \n",
    "           'study_submitted_date_qc', 'study_first_posted_date', 'available_completion_date', 'sponsor', \n",
    "           'ind_spon', 'drug_trial', 'phase_var', 'early_phase', 'late_phase', 'N/A', 'quartile_1', 'quartile_2', \n",
    "           'quartile_3', 'quartile_4']\n",
    "\n",
    "pr_df = df[pr_cats].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this accounts for when the reg requirement came fully into effect as of Sept 27, 2008\n",
    "pr_df['start_date_mod'] = np.where(pr_df.start_date < pd.Timestamp(2008,9,27), pd.Timestamp(2008,9,27) - pd.DateOffset(days=21),\n",
    "                                   pr_df.start_date.dt.date)\n",
    "\n",
    "#filter to check for trials registered within 21 days of the start date\n",
    "legal_check = pr_df.study_first_submitted_date > (pr_df.start_date_mod + pd.DateOffset(days=21))\n",
    "#1 means it was registered within the legal limit, 0 means in violation\n",
    "pr_df['legal_reg'] = np.where(legal_check, 0, 1)\n",
    "\n",
    "#filter to check for registration before the start date\n",
    "pros_check = pr_df.study_first_submitted_date > pr_df.start_date\n",
    "#1 means prospectively registered, 0 means retrospectively\n",
    "pr_df['pros_reg'] = np.where(pros_check, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{} trials out of {} ({}%) covered trials were registered late by the legal definition'.format(\n",
    "    len(pr_df[pr_df.legal_reg == 0]), len(pr_df), round(len(pr_df[pr_df.legal_reg == 0])/len(pr_df) * 100,2)))\n",
    "\n",
    "print('{} trials out of {} ({}%) covered trials were registered retrospectively'.format(\n",
    "    len(pr_df[pr_df.pros_reg == 0]), len(pr_df), round(len(pr_df[pr_df.pros_reg == 0])/len(pr_df) * 100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating days late to register by the legal standard\n",
    "\n",
    "legally_late = pr_df[pr_df.legal_reg == 0].reset_index(drop=True)\n",
    "legally_late['days_late'] = (legally_late.study_first_submitted_date - (legally_late.start_date_mod + pd.DateOffset(days=21))) / pd.Timedelta('1 day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting legal registration status by ACT/pACT status\n",
    "act_late = crosstab(pr_df, 'legal_reg','act_flag')\n",
    "act_late"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Percent of ACTs and pACTs registered late\n",
    "late_pacts = round((act_late.iloc[0, :][0] / (act_late.iloc[0, :][0] + act_late.iloc[0, :][1])) * 100,1)\n",
    "print(f\"{late_pacts}% of pACTs were registered late\")\n",
    "\n",
    "late_acts = round((act_late.iloc[1, :][0] / (act_late.iloc[1, :][0] + act_late.iloc[1, :][1])) * 100,1)\n",
    "print(f\"{late_acts}% of ACTs were registered late\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descriptive statistics for days late\n",
    "legally_late['days_late'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reg_bins = np.arange(0,int(legally_late['days_late'].max()) + 1, 100)\n",
    "reg_bins = np.arange(0,1100 + 1, 100)\n",
    "xlabels = ['0', '100', '200', '300', '400', '500', '600', '700', '800', '900', '1000+']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 15), dpi=300)\n",
    "ax.set_axisbelow(True)\n",
    "ax.grid(zorder=0)\n",
    "sns.distplot(np.clip(legally_late['days_late'],0,1000), hist=True, kde=False, bins=reg_bins, ax=ax,\n",
    "             hist_kws = {'zorder':10}).set(xlim=(0,1100))\n",
    "plt.xticks(reg_bins)\n",
    "ax.set_xticklabels(xlabels)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.tick_params(axis='both', which='major', labelsize=20)\n",
    "plt.ylabel('# of Trials', fontsize=25, labelpad=10)\n",
    "plt.xlabel('Days Late', fontsize=25, labelpad=10)\n",
    "plt.title(\"a. Days Registered Beyond the 21 Day Legal Limit\", pad = 20, fontsize = 30)\n",
    "#plt.savefig('figures/late_registration_1a.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outcome here is legal registration\n",
    "\n",
    "x_reg = pr_df[['act_flag', 'ind_spon', 'drug_trial', 'late_phase', 'N/A', \n",
    "               'quartile_2', 'quartile_3', 'quartile_4']].reset_index(drop=True)\n",
    "y_reg = pr_df['legal_reg'].reset_index(drop=True)\n",
    "\n",
    "conf = simple_logistic_regression(y_reg,x_reg,cis=.001)\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use this cell to check crude regression analysis of interest:\n",
    "\n",
    "crude_x = pr_df[['quartile_2', 'quartile_3', 'quartile_4']].reset_index(drop=True)\n",
    "\n",
    "simple_logistic_regression(y_reg,crude_x,cis=.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_rank = create_ranking(pr_df, 'legal_reg', marker=0)\n",
    "#r_top_10_prct = reg_rank.legal_reg.quantile(.95)\n",
    "reg_rank_merge = reg_rank.merge(covered_trials, on='sponsor')\n",
    "reg_rank_merge['prct'] = round((reg_rank_merge['legal_reg'] / reg_rank_merge['covered_trials']) * 100,2)\n",
    "\n",
    "#Check beyond top 10 to make sure no ties\n",
    "reg_rank_merge[reg_rank_merge.covered_trials >= 50].sort_values(by='prct', ascending=False).head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_by_year = pr_df[['study_first_submitted_date', 'legal_reg']].groupby(pr_df.study_first_submitted_date.dt.year).agg(['sum', 'count'])\n",
    "\n",
    "comp_by_year['prct_comp'] = round((comp_by_year['legal_reg']['sum'] / comp_by_year['legal_reg']['count']) * 100,2)\n",
    "\n",
    "reg_trends = comp_by_year[(comp_by_year.index >= 2009) & (comp_by_year.index <= 2019)]['prct_comp']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5), dpi=300)\n",
    "plt.plot(reg_trends, marker='o')\n",
    "plt.xticks(reg_trends.index)\n",
    "plt.yticks(range(0,101,10))\n",
    "plt.grid()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.ylabel('% FDAAA Compliant', fontsize=12, labelpad=5)\n",
    "plt.xlabel('Registration Year', fontsize=12, labelpad=7)\n",
    "plt.title(\"Compliant Registrations by Year Registered\", pad = 20, fontsize = 15)\n",
    "#plt.savefig('figures/reg_trends.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_by_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Last Verified Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['nct_id', 'has_results', 'pending_results', 'primary_completion_date', 'completion_date', 'study_first_posted_date', \n",
    "        'last_verified_date', 'last_updated_date', 'sponsor', 'act_flag', 'ind_spon', 'drug_trial', 'phase_var', \n",
    "        'early_phase', 'late_phase', 'N/A', 'quartile_1', 'quartile_2', 'quartile_3', 'quartile_4']\n",
    "update_dataset = df[cols].reset_index(drop=True)\n",
    "\n",
    "update_dataset['scrape_date'] = date(2020,1,17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logic for exclusion\n",
    "print('We start with all applicable trials: {}'.format(len(df)))\n",
    "\n",
    "#We exclude trials that were first posted to ClinicalTrials.gov within the last year \n",
    "#as they don't have a full year of follow-up\n",
    "exclude_under_a_year = update_dataset.study_first_posted_date >= pd.Timestamp(2019,1,17)\n",
    "print(\"Exclude {} for starting within the last year (since 17 Jan 2019)\".format(len(update_dataset[exclude_under_a_year])))\n",
    "new_excluded = update_dataset[~exclude_under_a_year].reset_index(drop=True)\n",
    "print(\"{} remaining\".format(len(new_excluded)))\n",
    "\n",
    "#We then exclude trials that have reached full completion as of the scrape date and have posted results.\n",
    "#The law frees you from your responsibility to verify once a year when you have posted all results following\n",
    "#completion of the trial\n",
    "complete_results = (new_excluded.completion_date < new_excluded.scrape_date) & (new_excluded.has_results == 1)\n",
    "print(\"Exclude {} for being completed with public results\".format(len(new_excluded[complete_results])))\n",
    "complete_excluded = new_excluded[~complete_results].reset_index(drop=True)\n",
    "print(\"{} remaining\".format(len(complete_excluded)))\n",
    "\n",
    "#Lastly we exclude trials with pending results as these likely have a newer verification that will appear once the\n",
    "#results complete QC review.\n",
    "print(\"Eclude {} for being currently pending\".format(len(complete_excluded[complete_excluded.pending_results==1])))\n",
    "cohort = complete_excluded[complete_excluded.pending_results == 0].reset_index(drop=True)\n",
    "print(\"{} remaining\".format(len(cohort)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dummy for late verification\n",
    "#Our data is from 17 Jan 2020 meaning verifications older than 17 January 2019 are officially out of date. \n",
    "#However, verifications are usually only provided in \"Month Year\" format with no date. As such, they are defaulted\n",
    "#to the beginning of the month. Conservatively, we will treat 1 January 2019 as our cutoff.\n",
    "\n",
    "# Late Verification = 1, Currently Verified = 0\n",
    "cohort['late_veri'] = np.where(cohort.last_verified_date < pd.Timestamp(2019,1,1), 1,0)\n",
    "late_veri = cohort.late_veri.sum()\n",
    "prct_late = round(cohort.late_veri.sum()/len(cohort)*100,1)\n",
    "print('{} of {} ({}%) of eligible trials are overdue to verify their records'.format(late_veri, len(cohort), prct_late))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#describing the days late for unverified trials\n",
    "\n",
    "cohort['verification_due'] = cohort.last_verified_date + pd.DateOffset(years=1)\n",
    "cohort['days_late'] = np.where(cohort.late_veri == 1, (pd.Timestamp(2020,1,1) - cohort.verification_due) / pd.Timedelta('1 day'), 0)\n",
    "cohort[cohort['late_veri'] == 1].days_late.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "late_with_update = len(cohort[(cohort.late_veri == 1) & (cohort.last_updated_date > pd.Timestamp(2019,1,17))])\n",
    "\n",
    "print('{} trials with a late verification updated since 1 January 2019'.format(late_with_update))\n",
    "print('This is {}% of the currently late trials'.format(round(late_with_update/late_veri * 100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reg_bins = np.arange(0,int(legally_late['days_late'].max()) + 1, 100)\n",
    "ver_bins = np.arange(0,1100 + 1, 100)\n",
    "xlabels = ['0', '100', '200', '300', '400', '500', '600', '700', '800', '900', '1000+']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 15), dpi=300)\n",
    "ax.set_axisbelow(True)\n",
    "ax.grid(zorder=0)\n",
    "sns.distplot(np.clip(cohort[cohort['late_veri'] == 1].days_late,0,1000), hist=True, kde=False, bins=ver_bins, ax=ax,\n",
    "             hist_kws = {'zorder':10}).set(xlim=(0,1100))\n",
    "plt.xticks(ver_bins)\n",
    "ax.set_xticklabels(xlabels)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.tick_params(axis='both', which='major', labelsize=20)\n",
    "plt.ylabel('# of Trials', fontsize=25, labelpad=10)\n",
    "plt.xlabel('Days Late', fontsize=25, labelpad=10)\n",
    "plt.title(\"b. Days Late to Verify Trial Data\", pad = 20, fontsize = 30)\n",
    "#plt.savefig('figures/last_verified_1b.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_veri = cohort.late_veri.replace({0:1, 1:0})\n",
    "x_veri = cohort[['act_flag', 'ind_spon', 'drug_trial', 'late_phase', 'N/A', 'quartile_2', \n",
    "                 'quartile_3', 'quartile_4']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outcome here is having a current verification date\n",
    "\n",
    "simple_logistic_regression(y_veri,x_veri, cis=.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use this cell to check crude regression analysis of interest:\n",
    "\n",
    "crude_x = cohort[['act_flag']].reset_index(drop=True)\n",
    "\n",
    "simple_logistic_regression(y_veri,crude_x,cis=.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veri_rank = create_ranking(cohort, 'late_veri')\n",
    "#v_top_10_prct = veri_rank.late_veri.quantile(.95)\n",
    "veri_rank_merge = veri_rank.merge(covered_trials, on='sponsor')\n",
    "veri_rank_merge['prct'] = round((veri_rank_merge['late_veri'] / veri_rank_merge['covered_trials']) * 100,2)\n",
    "\n",
    "veri_rank_merge[veri_rank_merge.covered_trials >= 50].sort_values(by='prct', ascending=False).head(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Certificate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cert_analysis = df[['nct_id','due_date', 'has_results', 'has_certificate', \"certificate_date_qc\", \"certificate_posted_date\",\n",
    "                    'certificate_date', 'late_cert', 'results_submitted_date_qc', 'sponsor', 'act_flag', 'ind_spon', 'drug_trial', \n",
    "                    'phase_var', 'early_phase', 'late_phase', 'N/A', 'quartile_1', 'quartile_2', 'quartile_3', \n",
    "                    'quartile_4']].reset_index(drop=True)\n",
    "\n",
    "#all_trials = df[['nct_id', 'due_date', 'results_due', 'has_certificate']].reset_index(drop=True)\n",
    "#all_trials['due_date'] = pd.to_datetime(all_trials.due_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "certificate = cert_analysis[cert_analysis.has_certificate == 1].reset_index(drop=True)\n",
    "all_certificates = certificate.nct_id.count()\n",
    "late_certificates = certificate.late_cert.sum()\n",
    "certificate['on_time_cert'] = np.where(certificate.late_cert==1, 0, 1)\n",
    "certs_with_results = certificate.has_results[certificate.has_results == 1].sum()\n",
    "late_certs_with_results = certificate.has_results[(certificate.has_results == 1) & (certificate.late_cert == 1)].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('As of 17 Jan 2020, {} ({}%) applicable trials had recieved Certificates of Delay out of {} applicable trials'\n",
    "      .format(all_certificates, round(all_certificates/len(df) * 100, 2), len(df)))\n",
    "print('{} of those {} ({}%) have results'\n",
    "      .format(certs_with_results, all_certificates, round(certs_with_results/all_certificates * 100,2)))\n",
    "print('{} of certificates were submitted late. That is {}% of all certificates'\n",
    "      .format(late_certificates, round((late_certificates/all_certificates)*100)))\n",
    "print('Of those submitted late, only {} have since posted any results, {}% of all late certificates'\n",
    "      .format(late_certs_with_results, round(late_certs_with_results/late_certificates * 100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#certificate['due_date'] = pd.to_datetime(certificate.due_date)\n",
    "#certificate['certificate_date'] = pd.to_datetime(certificate.certificate_date)\n",
    "#certificate['results_submitted_date_qc'] = pd.to_datetime(certificate.results_submitted_date_qc)\n",
    "certificate['scrape_date'] = pd.Timestamp(2019,11,1)\n",
    "certificate['days_late'] = certificate.certificate_date - certificate.due_date\n",
    "days_late_count = certificate.days_late[certificate.late_cert == 1] / pd.Timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_late_count.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{len(days_late_count[days_late_count > 100])} of {len(days_late_count)} trials with a \\\n",
    "late certificate were more than 100 days late to apply. That is \\\n",
    "{round((len(days_late_count[days_late_count > 100])/len(days_late_count))*100,1)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_bins = np.arange(0,450 + 1, 50)\n",
    "xlabels = ['0', '50', '100', '150', '200', '250', '300', '350', '400+']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 15), dpi=300)\n",
    "ax.set_axisbelow(True)\n",
    "ax.grid(zorder=0)\n",
    "sns.distplot(np.clip(days_late_count,0,400), hist=True, kde=False, bins=lc_bins, ax=ax,\n",
    "             hist_kws = {'zorder':10}).set(xlim=(0,450))\n",
    "ax.set_xticklabels(xlabels)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.tick_params(axis='both', which='major', labelsize=20)\n",
    "plt.ylabel('# of Trials', fontsize=25, labelpad=10)\n",
    "plt.xlabel('Days Late', fontsize=25, labelpad=10)\n",
    "plt.title(\"c. Days Late to Apply for Certificate of Delay\", pad = 20, fontsize = 30)\n",
    "#plt.savefig('figures/late_certificate_1c.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cert = certificate[['act_flag', 'ind_spon', 'drug_trial', 'late_phase', 'N/A', 'quartile_2', 'quartile_3', \n",
    "                      'quartile_4']].reset_index(drop=True)\n",
    "y_cert = certificate['on_time_cert'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outcome here is having an on-time certificate\n",
    "\n",
    "simple_logistic_regression(y_cert,x_cert, cis=.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use this cell to check crude regression analysis of interest:\n",
    "\n",
    "crude_x = certificate[['quartile_2', 'quartile_3', 'quartile_4']].reset_index(drop=True)\n",
    "\n",
    "simple_logistic_regression(y_cert,crude_x,cis=.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cert_rank = create_ranking(certificate, 'late_cert')\n",
    "#c_top_10_prct = cert_rank.late_cert.quantile(.95)\n",
    "cert_rank_merge = cert_rank.merge(covered_trials, on='sponsor')\n",
    "cert_rank_merge['prct'] = round((cert_rank_merge['late_cert'] / cert_rank_merge['covered_trials']) * 100,2)\n",
    "cert_rank_merge[cert_rank_merge.covered_trials >= 50].sort_values(by='prct', ascending=False).reset_index(drop=True).head(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QC Data\n",
    "\n",
    "From the FDAAA TrialsTracker, we had some detailed data available we scraped ourselves but not across all appliable trials, only trials that became due. Data on, at the very least, the time between first submission, final submission and posting date can be garnered for every applicable trial directly from the raw data.\n",
    "\n",
    "Given that this field is not preserved in the raw XML once results complete the QC process, this database was created through manual assessment of current and historic data both held by the DataLab and on the ClincialTrials.gov archive site. The Notebook `QC Expansion` can aid in recreating the pending data timeline for all trials that were pending on a given date from a processed data file such as the one created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cutting down our full dataset with only what we need for the QC analysis\n",
    "\n",
    "qc_cols = ['nct_id', 'results_due', 'due_date', 'available_completion_date', 'primary_completion_date', 'completion_date', \n",
    "           'certificate_date', 'last_updated_date', 'results_first_submitted_date', 'results_submitted_date_qc', \n",
    "           'results_first_posted_date', 'sponsor', 'act_flag', 'ind_spon', 'drug_trial', 'phase_var', 'early_phase', \n",
    "           'late_phase', 'N/A', 'quartile_1', 'quartile_2', 'quartile_3', 'quartile_4']\n",
    "xml_data = df[qc_cols].reset_index(drop=True)\n",
    "    \n",
    "#Calling in our QC data\n",
    "data = pd.read_excel(parent + '/data/new_qc_dataset.xlsx', sheet_name='qc_data')\n",
    "data['scrape_date'] = pd.Timestamp(2020,1,17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This creates new columns that details the days between each step in the QC process. This details the time between \n",
    "#each submission, return and then subsequent resubmission\n",
    "\n",
    "sub = 1\n",
    "ret = 1\n",
    "cols = list(range(4,34))\n",
    "for col in cols:\n",
    "    if col % 2 == 0:\n",
    "        col_name = 'db_sub{}_ret{}'.format(sub, ret)\n",
    "        sub += 1\n",
    "    else:\n",
    "        col_name = 'db_ret{}_sub{}'.format(ret, sub)\n",
    "        ret += 1\n",
    "    data[col_name] = (data.iloc[:,col+1] - data.iloc[:,col]) / pd.Timedelta('1 day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging the fields taken from the XML with the detailed QC data.\n",
    "\n",
    "qc_data = data.merge(xml_data, how='left', on='nct_id')\n",
    "    \n",
    "#Creating some fields we will need\n",
    "qc_data['time_to_results'] = (qc_data.results_first_posted_date - qc_data.results_first_submitted_date) / pd.Timedelta('1 day')\n",
    "qc_data['time_to_results_nc'] = (qc_data.results_first_posted_date - qc_data.first_sub_nc) / pd.Timedelta('1 day')\n",
    "qc_data['ever_cancelled'] = np.where(qc_data.cancelled_details.notnull(),1,0)\n",
    "qc_data['inferred_data'] = qc_data.inferred_data.replace(np.nan, '')\n",
    "\n",
    "#Putting the columns in a sensible order to work with\n",
    "col_order = ['nct_id', 'qc_data_status', 'cancelled_details', 'first_sub_any', 'first_sub_nc', 'db_sub1_ret1',\n",
    "             'qc1_return', 'db_ret1_sub2', 'second_sub', 'db_sub2_ret2', 'qc2_return', 'db_ret2_sub3', 'third_sub',\n",
    "             'db_sub3_ret3', 'qc3_return', 'db_ret3_sub4', 'fourth_sub', 'db_sub4_ret4', 'qc4_return', \n",
    "             'db_ret4_sub5', 'fifth_sub', 'db_sub5_ret5', 'qc5_return', 'db_ret5_sub6', 'sixth_sub', 'db_sub6_ret6', \n",
    "             'qc6_return', 'db_ret6_sub7', 'seventh_sub', 'db_sub7_ret7', 'qc7_return', 'db_ret7_sub8', \n",
    "             'eighth_sub', 'db_sub8_ret8', 'qc8_return', 'db_ret8_sub9', 'ninth_sub', 'db_sub9_ret9', 'qc9_return', \n",
    "             'db_ret9_sub10', 'tenth_sub', 'db_sub10_ret10', 'qc10_return', 'db_ret10_sub11', 'eleventh_sub', \n",
    "             'db_sub11_ret11', 'qc11_return', 'db_ret11_sub12', 'twelfth_sub', 'db_sub12_ret12', 'qc12_return', \n",
    "             'db_ret12_sub13', 'thirteenth_sub', 'db_sub13_ret13', 'qc13_return', 'db_ret13_sub14', 'fourteenth_sub', \n",
    "             'db_sub14_ret14', 'qc14_return', 'db_ret14_sub15', 'fifteenth_sub', 'db_sub15_ret15', 'qc15_return', \n",
    "             'db_ret15_sub16', 'sixteenth_sub', 'inferred_data', 'scrape_date', 'results_due', 'due_date', \n",
    "             'available_completion_date', 'primary_completion_date', 'completion_date', 'certificate_date', \n",
    "             'last_updated_date', 'results_first_submitted_date', 'results_submitted_date_qc', \n",
    "             'results_first_posted_date', 'time_to_results', 'time_to_results_nc', 'ever_cancelled', 'sponsor', 'act_flag', \n",
    "             'ind_spon', 'drug_trial', 'phase_var', 'early_phase', 'late_phase', 'N/A', 'quartile_1', \n",
    "             'quartile_2', 'quartile_3', 'quartile_4']\n",
    "\n",
    "qc_data = qc_data[col_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rid of trials that cancelled their first round submission and never resubmitted and get new look at counts\n",
    "#NCT02684136\n",
    "#NCT03134703\n",
    "#NCT02176928\n",
    "\n",
    "qc_data = qc_data[qc_data.first_sub_nc.notnull()].reset_index(drop=True)\n",
    "\n",
    "qc_data[['nct_id','qc_data_status']].groupby(by='qc_data_status').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_survivorship = qc_data[['nct_id', 'scrape_date', 'results_first_posted_date', 'first_sub_nc']].reset_index(drop=True)\n",
    "qc_survivorship['posted_results'] = np.where(qc_survivorship.results_first_posted_date.notnull(), 1, 0)\n",
    "qc_survivorship['days_to_posted'] = qc_survivorship.results_first_posted_date - qc_survivorship.first_sub_nc\n",
    "qc_survivorship['censored'] = qc_survivorship.scrape_date - qc_survivorship.first_sub_nc\n",
    "qc_survivorship.loc[qc_survivorship['posted_results'] == 1, 'censored'] = None\n",
    "qc_survivorship['duration'] = np.where(qc_survivorship.censored.notnull(), \n",
    "                                       qc_survivorship.censored, qc_survivorship.days_to_posted)\n",
    "\n",
    "#import lifelines\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lib.lifelines_fix import add_at_risk_counts\n",
    "\n",
    "fig = plt.figure(dpi=300)\n",
    "ax = plt.subplot()\n",
    "\n",
    "\n",
    "yticks = list(np.arange(0,1.1,.1))\n",
    "kmf = KaplanMeierFitter()\n",
    "kmf.fit((qc_survivorship['duration'] / pd.Timedelta('1 day')), qc_survivorship['posted_results'].astype(float))\n",
    "ax = kmf.plot(ci_show=False, figsize=(15,10), grid=True, show_censors=True, censor_styles={'ms':10, 'marker':'|'},\n",
    "              yticks = yticks, legend=False, ax=ax, lw=2.5)\n",
    "\n",
    "ax.tick_params(labelsize=15)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "plt.title(\"Time From Submission to Posting of Results on ClinicalTrials.gov for Applicable Trials\", pad=20, fontsize=20)\n",
    "plt.ylabel('Proportion Not Posted', labelpad=10, fontsize=15)\n",
    "plt.xlabel('Days From Submission', labelpad=10, fontsize=15)\n",
    "add_at_risk_counts(14, kmf, labels=None)\n",
    "#plt.savefig('figures/qc_km_curve.svg')\n",
    "\n",
    "print('Median time to report: {} days'.format(kmf.median_survival_time_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This provides the values for the 95% CI at the median\n",
    "from lifelines.utils import median_survival_times\n",
    "median_survival_times(kmf.confidence_interval_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify columns for returns and resubmissions for later filtering and analysis\n",
    "\n",
    "ctgov_returns = ['db_sub1_ret1', 'db_sub2_ret2', 'db_sub3_ret3', 'db_sub4_ret4', 'db_sub5_ret5', 'db_sub6_ret6',\n",
    "               'db_sub7_ret7', 'db_sub8_ret8', 'db_sub9_ret9', 'db_sub10_ret10', 'db_sub11_ret11', 'db_sub12_ret12',\n",
    "               'db_sub13_ret13', 'db_sub14_ret14', 'db_sub15_ret15']\n",
    "\n",
    "sponsor_subs = ['db_ret1_sub2', 'db_ret2_sub3', 'db_ret3_sub4', 'db_ret4_sub5', 'db_ret5_sub6', 'db_ret6_sub7', \n",
    "                 'db_ret7_sub8', 'db_ret8_sub9', 'db_ret9_sub10', 'db_ret10_sub11', 'db_ret11_sub12', \n",
    "                 'db_ret12_sub13', 'db_ret13_sub14', 'db_ret14_sub15', 'db_ret15_sub16']\n",
    "\n",
    "qc_returns = ['qc1_return', 'qc2_return', 'qc3_return', 'qc4_return', 'qc5_return', 'qc6_return', 'qc7_return', 'qc8_return',\n",
    "             'qc9_return', 'qc10_return', 'qc11_return', 'qc12_return', 'qc13_return', 'qc14_return', 'qc15_return']\n",
    "\n",
    "qc_submissions = ['first_sub_nc', 'second_sub', 'third_sub', 'fourth_sub', 'fifth_sub', 'sixth_sub', 'seventh_sub', 'eighth_sub',\n",
    "                 'ninth_sub', 'tenth_sub', 'eleventh_sub', 'twelfth_sub', 'thirteenth_sub', 'fourteenth_sub', 'fifteenth_sub',\n",
    "                 'sixteenth_sub']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that does a quick check for re-submission delays longer than the 25 day legal deadline\n",
    "def late_check(x):\n",
    "    return(x > 25)\n",
    "\n",
    "#Applying this function across all the sponsor re-submissions to flag when they contain a late resubmission at all\n",
    "qc_data['ever_late_resub'] = np.where(qc_data[sponsor_subs].apply(late_check).any(axis=1),1,0)\n",
    "\n",
    "#Counting how many re-submission were late for each trial\n",
    "qc_data['total_late_subs'] = (qc_data[sponsor_subs] > 25).sum(axis=1)\n",
    "\n",
    "#Counting the numbers of submissions and returns\n",
    "qc_data['submissions'] = qc_data[qc_submissions].notnull().sum(axis=1)\n",
    "qc_data['returns'] = qc_data[qc_returns].notnull().sum(axis=1)\n",
    "\n",
    "#If a trial has results, this gets the time between the last submission and the posting of results which is essentially\n",
    "#Another round of ClinicalTrials.gov review but without a return\n",
    "qc_data['final_review'] = np.where(qc_data.results_first_posted_date.notnull(), \n",
    "                                   (qc_data.results_first_posted_date - qc_data.results_submitted_date_qc) / \n",
    "                                   pd.Timedelta('1 day'), None)\n",
    "\n",
    "#The latest return date\n",
    "qc_data['max_return'] = qc_data[qc_returns].max(axis=1)\n",
    "\n",
    "\n",
    "#For trials that are currently pending, this gets the current days between the most recent QC return and \n",
    "#the date of this dataset\n",
    "qc_data['cur_sub_day_outstanding'] = np.where((qc_data.returns == qc_data.submissions) & \n",
    "                                              (qc_data.qc_data_status == 'Pending'), \n",
    "                                             (qc_data.scrape_date - qc_data.max_return) / pd.Timedelta(days=1), np.nan)\n",
    "\n",
    "#This looks for trials that have always been compliant, even if you consider currently outstanding re-submissions\n",
    "qc_data['always_compliant'] = np.where((qc_data.cur_sub_day_outstanding < 25) & (qc_data.ever_late_resub == 0), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This summarizes which trials have detailed QC data available for further analysis, and which do not.\n",
    "\n",
    "pending_all = len(qc_data[(qc_data.qc_data_status == \"Pending\") | \n",
    "                      (qc_data.qc_data_status == \"Currently Canceled\")])\n",
    "available_all = len(qc_data[(qc_data.qc_data_status == \"Results Available\") | \n",
    "                            (qc_data.qc_data_status == 'No Detailed QC Available')])\n",
    "\n",
    "\n",
    "print(f\"{len(qc_data)} ({round((len(qc_data))/len(df) * 100,1)}%) of {len(df)} covered trials \\\n",
    "have results submitted or available\")\n",
    "\n",
    "print(f\"{pending_all} are pending ({round((pending_all)/len(qc_data) * 100,1)}%)\")\n",
    "\n",
    "print(f\"{available_all} are available ({round(available_all/len(qc_data) * 100,1)}%)\")\n",
    "\n",
    "never_pub = len(qc_data[qc_data.qc_data_status == 'No Detailed QC Available'])\n",
    "\n",
    "print((f'''{never_pub} trials ({round(never_pub/len(qc_data) * 100,1)}%) do not have detailed QC data available'''))\n",
    "\n",
    "trials_left = (len(qc_data) - len(qc_data[qc_data.qc_data_status == 'No Detailed QC Available']))\n",
    "\n",
    "print(f\"This leaves {trials_left} ({round(trials_left/len(qc_data) * 100,1)}%) with detailed quality control \\\n",
    "information available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the dataset of only trials with detailed QC data we will use for the remaining analysis\n",
    "qc_stats_detailed = qc_data[(qc_data.qc_data_status != 'No Detailed QC Available')].reset_index(drop=True)\n",
    "\n",
    "#Describing trials with full Results Available\n",
    "qc_d = len(qc_stats_detailed)\n",
    "\n",
    "qc_full_results = len(qc_stats_detailed[qc_stats_detailed.results_first_posted_date.notnull()])\n",
    "\n",
    "print(f\"Among the {qc_d} trials with detailed QC data available, {qc_full_results} \\\n",
    "({round(qc_full_results/qc_d *100,1)}%) have full results available.\")\n",
    "\n",
    "#Stats about submissions for trials with full results\n",
    "qc_stats_detailed[qc_stats_detailed.results_first_posted_date.notnull()].submissions.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stats about the submission of pending data\n",
    "\n",
    "print(f\"{pending_all} trials are currently plending\")\n",
    "\n",
    "#Stats about submissions for pending trials\n",
    "qc_stats_detailed[qc_stats_detailed.results_first_posted_date.isnull()].submissions.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building some variable to describe the QC process\n",
    "\n",
    "curr_pend_qc = qc_stats_detailed[(qc_stats_detailed.qc_data_status == \"Pending\") | \n",
    "                                 (qc_stats_detailed.qc_data_status == \"Currently Canceled\")]\n",
    "\n",
    "print(f\"{len(curr_pend_qc)} trials are currently pending\")\n",
    "\n",
    "cur_out_100 = len(curr_pend_qc[curr_pend_qc.cur_sub_day_outstanding > 100])\n",
    "\n",
    "cur_late = len(curr_pend_qc[curr_pend_qc.cur_sub_day_outstanding > 25])\n",
    "\n",
    "print(f\"{cur_late} ({round(cur_late/len(curr_pend_qc) * 100,1)}%) currently outstanding trials are over 25 days outstanding\")\n",
    "\n",
    "print(f\"{cur_out_100} ({round(cur_out_100/len(curr_pend_qc) * 100,1)}%) currently outstanding trials are over 100 days outstanding\")\n",
    "\n",
    "print(\"Stats on trials that are currently outstanding:\")\n",
    "curr_pend_qc.cur_sub_day_outstanding.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_bins = np.arange(0,450 + 1, 25)\n",
    "xlabels = ['0', '25', '50', '75', '100', '125', '150', '175', '200', '225', '250', '275', '300', '325', '350', '375', '400+']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 15), dpi=300)\n",
    "ax.set_axisbelow(True)\n",
    "ax.grid(zorder=0)\n",
    "sns.distplot(np.clip(curr_pend_qc.cur_sub_day_outstanding,0,400), hist=True, kde=False, bins=qc_bins, ax=ax,\n",
    "             hist_kws = {'zorder':10}).set(xlim=(0,425))\n",
    "ax.set_xticklabels(xlabels)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.xticks(qc_bins[:-2])\n",
    "plt.tick_params(axis='both', which='major', labelsize=20)\n",
    "plt.ylabel('# of Trials', fontsize=25, labelpad=10)\n",
    "plt.xlabel('Days Since QC Return', fontsize=25, labelpad=10)\n",
    "plt.title(\"d. Days Currently Outsanding for Pending Trials (n=601)\", pad = 20, fontsize = 30)\n",
    "#plt.savefig('figures/qc_pending_delay_1d.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Submission Stats\n",
    "\n",
    "#all submissions includes the first submission (that cannot be late) so we need to subtract these \n",
    "#out when we only want to talk about re-submissions\n",
    "resubmission_count = qc_stats_detailed.submissions.sum() - len(qc_stats_detailed)\n",
    "\n",
    "print(f\"There were {resubmission_count} resubmission after returns from ClincialTrials.gov staff\")\n",
    "\n",
    "late_resubs = qc_stats_detailed.total_late_subs.sum()\n",
    "\n",
    "print(f\"{late_resubs} ({round(late_resubs/resubmission_count * 100,1)}%) were more than 25 days late to resubmit\")\n",
    "\n",
    "over_100_spon = len(qc_stats_detailed[sponsor_subs].stack()[qc_stats_detailed[sponsor_subs].stack() > 100])\n",
    "\n",
    "print(f\"{over_100_spon } ({round(over_100_spon/resubmission_count * 100)}%) \\\n",
    "did not resubmit until after more than 100 days\")\n",
    "\n",
    "ever_late = qc_stats_detailed.ever_late_resub.sum()\n",
    "\n",
    "print(f\"The late resubmissions were spread out over {ever_late} ({round(ever_late/resubmission_count * 100,1)}%) \\\n",
    "of trials with complete QC information\")\n",
    "\n",
    "qc_stats_detailed[sponsor_subs].stack().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qc2_bins = np.arange(0,250 + 1, 25)\n",
    "xlabels = ['0', '25', '50', '75', '100', '125', '150', '175', '200+']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 15), dpi=300)\n",
    "ax.set_axisbelow(True)\n",
    "ax.grid(zorder=0)\n",
    "sns.distplot(np.clip(qc_stats_detailed[sponsor_subs].stack(),0,200), hist=True, kde=False, bins=qc2_bins, ax=ax,\n",
    "             hist_kws = {'zorder':10}).set(xlim=(0,225))\n",
    "ax.set_xticklabels(xlabels)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.xticks(qc2_bins[:-2])\n",
    "plt.tick_params(axis='both', which='major', labelsize=20)\n",
    "plt.ylabel('# of Trials', fontsize=25, labelpad=10)\n",
    "plt.xlabel('Days to Resubmission', fontsize=25, labelpad=10)\n",
    "plt.title(\"e. Time to Resubmission for Returned QC Results\", pad = 20, fontsize = 30)\n",
    "#plt.savefig('figures/qc_rounds_1e.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets get all trials with full results:\n",
    "\n",
    "trials_with_results = qc_stats_detailed[(qc_stats_detailed.results_first_posted_date.notnull())].reset_index(drop=True)\n",
    "\n",
    "results_one_submission = trials_with_results[(trials_with_results.submissions == 1) & (trials_with_results.returns == 0)]\n",
    "\n",
    "results_multiple_submission = trials_with_results[(trials_with_results.submissions > 1)]\n",
    "\n",
    "print(f\"Results posted after first submission: {round(((len(results_one_submission)/len(trials_with_results)) * 100),2)}%\")\n",
    "\n",
    "#This is the descriptive statistics for trials that had results made available after a single round of review.\n",
    "results_one_submission.time_to_results_nc.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This tells us the statistics for all first round submissions whether they led to results or a return\n",
    "results_multiple_submission.db_sub1_ret1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This tells us the statistics for additional rounds of review after the first round\n",
    "(results_multiple_submission.submissions - 1).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This gives us the average number of days added per resubmission\n",
    "\n",
    "num_resubs = trials_with_results.submissions - 1\n",
    "resub_days = trials_with_results.time_to_results_nc - trials_with_results.db_sub1_ret1\n",
    "\n",
    "resub_days.sum() / num_resubs.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_stats_detailed['never_late_resub'] = np.where((qc_stats_detailed.ever_late_resub == 0) & \n",
    "                                                 (qc_stats_detailed.cur_sub_day_outstanding < 25),1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The outcome here is trials that never had a late resubmission during QC\n",
    "\n",
    "x_qc = qc_stats_detailed[['act_flag', 'ind_spon', 'drug_trial', 'late_phase', \n",
    "                          'N/A', 'quartile_2', 'quartile_3', 'quartile_4']].reset_index(drop=True)\n",
    "y_qc = qc_stats_detailed['never_late_resub'].reset_index(drop=True)\n",
    "\n",
    "conf = simple_logistic_regression(y_qc,x_qc, cis=.001)\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use this cell to check crude regression analysis of interest:\n",
    "\n",
    "crude_x = qc_stats_detailed[['act_flag']].reset_index(drop=True)\n",
    "\n",
    "simple_logistic_regression(y_qc,crude_x,cis=.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_rank = create_ranking(qc_stats_detailed, 'never_late_resub', marker=0)\n",
    "qc_rank_merge = qc_rank.merge(covered_trials, on='sponsor')\n",
    "qc_rank_merge['prct'] = round((qc_rank_merge['never_late_resub'] / qc_rank_merge['covered_trials']) * 100,2)\n",
    "qc_rank_merge[qc_rank_merge.covered_trials >= 50].sort_values(by='prct', ascending=False).head(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Zarin et al. 2019 Comparison:</b> \n",
    "\n",
    "During peer review we were asked to compare our QC findings on first-submission success to Zarin et al. 2019. This piece used a slightly different methodology to examine this compared to ours. Specifically it didn't restrict the analysis to trials with results. This uses a comprable method and looks at the split between industry and non-industry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "just_pending = qc_data[(qc_data.qc_data_status == \"Pending\") | \n",
    "                       (qc_data.qc_data_status == \"Currently Canceled\")].reset_index(drop=True)\n",
    "\n",
    "pending_returned = just_pending[just_pending.returns != 0]\n",
    "print(f\"There are {len(pending_returned)} trials that are pending and we know were not successful in round 1\")\n",
    "print(f\"{len(pending_returned[pending_returned.ind_spon==1])} of these from industry and \\\n",
    "{len(pending_returned[pending_returned.ind_spon==0])} from non-industry\")\n",
    "\n",
    "print(f\"Overall first round compliance, including these trials, was {round((len(results_one_submission)/(len(trials_with_results) + len(pending_returned)) * 100),1)}%\")\n",
    "\n",
    "ind_denom = len(trials_with_results[trials_with_results.ind_spon==1]) + len(pending_returned[pending_returned.ind_spon==1])\n",
    "ind_num = len(results_one_submission[results_one_submission.ind_spon==1])\n",
    "\n",
    "non_ind_denom = len(trials_with_results[trials_with_results.ind_spon==0]) + len(pending_returned[pending_returned.ind_spon==0])\n",
    "non_ind_num = len(results_one_submission[results_one_submission.ind_spon==0])\n",
    "\n",
    "print(f\"For industry sponsors {round((ind_num/ind_denom) * 100,2)}% succeeded on the first try\")\n",
    "print(f\"For non-industry sponsors {round((non_ind_num/non_ind_denom) * 100,2)}% succeeded on the first try\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_df = df[['nct_id', 'results_due', 'has_results', 'pending_results', 'has_certificate','results_first_submitted_date', \n",
    "             'results_first_posted_date','primary_completion_date', 'due_date', 'last_updated_date', 'documents', 'sponsor',\n",
    "             'act_flag','ind_spon', 'drug_trial', 'phase_var', 'early_phase', 'late_phase', 'N/A', 'quartile_1', \n",
    "             'quartile_2', 'quartile_3', 'quartile_4']].reset_index(drop=True)\n",
    "\n",
    "doc_df['has_documents'] = np.where(doc_df.documents.notnull(), 1,0)\n",
    "doc_df['results_first_submitted_date'] = pd.to_datetime(doc_df['results_first_submitted_date'])\n",
    "doc_df['primary_completion_date'] = pd.to_datetime(doc_df['primary_completion_date'])\n",
    "doc_df['due_date'] = pd.to_datetime(doc_df['due_date'])\n",
    "doc_df['last_updated_date'] = pd.to_datetime(doc_df['last_updated_date'])\n",
    "doc_df['results_first_posted_date'] = pd.to_datetime(doc_df['results_first_posted_date'])\n",
    "doc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Describing the population\n",
    "\n",
    "due_and_docs = len(doc_df[(doc_df.results_due == 1) & (doc_df.has_documents == 1)])\n",
    "due_docs_reported = len(doc_df[(doc_df.results_due == 1) & (doc_df.has_documents == 1) & (doc_df.has_results == 1)])\n",
    "results_no_docs = len(doc_df[(doc_df.results_due == 1) & (doc_df.has_documents == 0) & (doc_df.has_results == 1)])\n",
    "no_results_docs = len(doc_df[(doc_df.results_due == 1) & (doc_df.has_documents == 1) & (doc_df.has_results == 0) ])\n",
    "check = len(doc_df[(doc_df.results_due == 1) & (doc_df.has_documents == 0) & (doc_df.has_results == 0) & (doc_df.pending_results==1)])\n",
    "results_due = doc_df.results_due.sum()\n",
    "print('{} Trials are due to report results, and therefore should have uploaded a protocol and SAP'.format(results_due))\n",
    "print('Of these {} due trials have any documents, {} due trials have both documents and results'.format(due_and_docs,due_docs_reported))\n",
    "print('{} due trials have documents but no results, {} have no documents but results'.format(no_results_docs, results_no_docs))\n",
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_docs_df = doc_df[['nct_id', 'documents']][doc_df.has_documents == 1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_docs_ids = has_docs_df.nct_id.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this makes each document it's own row with nct_id as the index\n",
    "dfs_list = []\n",
    "import ast\n",
    "has_docs = has_docs_df.copy()\n",
    "has_docs['documents'] = has_docs['documents'].apply(ast.literal_eval)\n",
    "for index, row in has_docs.iterrows():\n",
    "    if isinstance(has_docs['documents'][index], list):\n",
    "        l = len(has_docs['documents'][index])\n",
    "        ix = [has_docs['nct_id'][index]] * l\n",
    "        interim_df = pd.DataFrame(has_docs['documents'][index], index = ix)\n",
    "        dfs_list.append(interim_df)\n",
    "    else:\n",
    "        interim_df = pd.DataFrame(has_docs['documents'][index], index = [has_docs['nct_id'][index]])\n",
    "        dfs_list.append(interim_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Further processing\n",
    "nct_index_df = pd.concat(dfs_list, sort=True)\n",
    "nct_index_df = nct_index_df.reset_index(level=0)\n",
    "nct_index_df.rename(columns= {nct_index_df.columns[0]: \"nct_id\"}, inplace=True)\n",
    "\n",
    "#fixing a small incorrect data point that came up in summary review of data\n",
    "#(verfified in document https://clinicaltrials.gov/ProvidedDocs/10/NCT01866410/Prot_SAP_000.pdf)\n",
    "bad_index = nct_index_df.index[nct_index_df['document_date'] == 'January 24, 1014'].tolist()[0]\n",
    "nct_index_df.at[bad_index,'document_date'] = 'January 24, 2014'\n",
    "\n",
    "nct_index_df['document_date'] = pd.to_datetime(nct_index_df['document_date'])\n",
    "nct_index_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The first time you run this notebook on a new dataset, you can get the data on when the documents \n",
    "#were last updated by importing and running the \"history_scrape\" function. However, if you are using \n",
    "#the shared data from the project or re-running a prior analysis you can just export and save a CSV that \n",
    "#you can then re-load.\n",
    "\n",
    "#If you already have the output from the above exported to CSV, just run this cell pointing to that file\n",
    "#if it isn't already in the same directory (this will work assuming no changed to the clones repo)\n",
    "\n",
    "try:\n",
    "    docs_updates = pd.read_csv(parent + '/data/history_scrape_2020-01-17.csv')\n",
    "except FileNotFoundError:\n",
    "    from lib.trial_history import history_scrape\n",
    "    most_recent_doc_update = history_scrape(tqdm(has_docs_ids), date(2020,1,17))\n",
    "    docs_updates = pd.DataFrame(most_recent_doc_update)\n",
    "    docs_updates.to_csv('history_scrape_{}.csv'.format(date(2020,1,17)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning and managing the scraped data as above\n",
    "bad_index = docs_updates.index[docs_updates['document_date'] == 'January 24, 1014'].tolist()[0]\n",
    "docs_updates.at[bad_index,'document_date'] = 'January 24, 2014'\n",
    "docs_updates['upload_date'] = pd.to_datetime(docs_updates['upload_date'])\n",
    "docs_updates['document_date'] = pd.to_datetime(docs_updates['document_date'])\n",
    "docs_updates['version_date'] = pd.to_datetime(docs_updates['version_date'])\n",
    "docs_updates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For ease of analysis we set dummy dates, for submission dates not scraped, \n",
    "#either very far in the past or future. This makes determining the earliest and latest\n",
    "#submission dates much easier during grouping in the next step\n",
    "full_docs_df = nct_index_df.merge(docs_updates, on=['nct_id', 'document_date', 'document_type'])\n",
    "full_docs_df['dummy_date_past'] = pd.to_datetime(-2208988800, unit='s')\n",
    "full_docs_df['dummy_date_future'] = pd.to_datetime(4102444800, unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting to 1 line per trial\n",
    "\n",
    "def f(x):\n",
    "    d = {}\n",
    "    d['number_of_documents'] = x.nct_id.count()\n",
    "    d['num_protocol_docs'] = np.where(x.document_has_protocol == 'Yes',1,0).sum()\n",
    "    d['num_sap_docs'] = np.where(x.document_has_sap == 'Yes',1,0).sum()\n",
    "    d['has_protocol'] = np.where(((np.where(x.document_has_protocol == 'Yes',1,0).sum())>0),1,0)\n",
    "    d['has_sap'] = np.where(((np.where(x.document_has_sap == 'Yes',1,0).sum())>0),1,0)\n",
    "    d['no_sap'] = np.where((np.where(x.no_sap.notnull(), 1, 0).sum() > 0), 1, 0)\n",
    "    d['first_protocol_submitted'] = np.where(x.document_has_protocol == 'Yes', x.upload_date,x.dummy_date_future).min()\n",
    "    d['latest_protocol_submitted'] = np.where(x.document_has_protocol == 'Yes', x.upload_date,x.dummy_date_past).max()\n",
    "    d['first_sap_submitted'] = np.where(x.document_has_sap == 'Yes', x.upload_date,x.dummy_date_future).min()\n",
    "    d['latest_sap_submitted'] = np.where(x.document_has_sap == 'Yes', x.upload_date,x.dummy_date_past).max()\n",
    "    return pd.Series(d)\n",
    "\n",
    "grouped = full_docs_df.groupby('nct_id').apply(f).reset_index()\n",
    "\n",
    "#Now we can easily replace those far in the future/past dates with nulls\n",
    "grouped.loc[grouped['latest_protocol_submitted'] == '1900-01-01', 'latest_protocol_submitted'] = pd.NaT\n",
    "grouped.loc[grouped['latest_sap_submitted'] == '1900-01-01', 'latest_sap_submitted'] = pd.NaT\n",
    "grouped.loc[grouped['first_protocol_submitted'] == '2100-01-01', 'first_protocol_submitted'] = pd.NaT\n",
    "grouped.loc[grouped['first_sap_submitted'] == '2100-01-01', 'first_sap_submitted'] = pd.NaT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bringing in additional data we need for further analysis\n",
    "\n",
    "more_cols = ['nct_id', 'results_due', 'has_results', 'pending_results', 'primary_completion_date', 'due_date', \n",
    "             'results_first_submitted_date', 'results_first_posted_date', 'last_updated_date', 'ind_spon', 'drug_trial', \n",
    "             'phase_var', 'sponsor', 'act_flag', 'early_phase', 'late_phase', 'N/A', 'quartile_1', 'quartile_2', 'quartile_3', \n",
    "             'quartile_4']\n",
    "merged = doc_df[more_cols].merge(grouped, how='left', on='nct_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data cleaning\n",
    "merged.number_of_documents.fillna(0, inplace=True)\n",
    "merged.num_protocol_docs.fillna(0, inplace=True)\n",
    "merged.num_sap_docs.fillna(0, inplace=True)\n",
    "merged.has_protocol.fillna(0, inplace=True)\n",
    "merged.has_sap.fillna(0, inplace=True)\n",
    "merged.no_sap.fillna(0, inplace=True)\n",
    "merged['prot_after_completion'] = np.where(merged.latest_protocol_submitted > merged.primary_completion_date, 1, 0)\n",
    "merged['sap_after_completion'] = np.where(merged.latest_sap_submitted > merged.primary_completion_date, 1, 0)\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filters\n",
    "\n",
    "due_reported_filt = ((merged.results_due == 1) & (merged.has_results == 1))\n",
    "\n",
    "due_unreported_filt = (merged.results_due == 1) & (merged.has_results == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building various counts to describe the population below\n",
    "\n",
    "all_due = len(merged[(merged.results_due == 1)])\n",
    "\n",
    "due_results = len(merged[due_reported_filt])\n",
    "\n",
    "prot_and_sap = len(merged[due_reported_filt & (merged.has_protocol == 1) & (merged.has_sap == 1)])\n",
    "\n",
    "just_prot = len(merged[due_reported_filt & (merged.has_protocol == 1) & (merged.has_sap == 0)])\n",
    "\n",
    "due_results_new_prot = len(merged[(due_reported_filt & (merged.has_protocol == 1) & (merged.prot_after_completion == 1))])\n",
    "\n",
    "due_results_new_sap = len(merged[(due_reported_filt & (merged.has_sap == 1) & (merged.sap_after_completion == 1))])\n",
    "\n",
    "just_sap = len(merged[due_reported_filt & (merged.has_protocol == 0) & (merged.has_sap == 1)])\n",
    "\n",
    "no_sap_statement = len(merged[due_reported_filt & ((merged.has_protocol == 1) & (merged.has_sap == 0) & (merged.no_sap == 1))])\n",
    "\n",
    "due_results_no_docs = len(merged[due_reported_filt & (merged.has_protocol == 0) & (merged.has_sap == 0)])\n",
    "\n",
    "docs_accounted = len(merged[due_reported_filt & ((merged.has_protocol == 1) | (merged.has_sap == 1))])\n",
    "\n",
    "due_no_results = len(merged[due_unreported_filt])\n",
    "\n",
    "due_no_results_docs = len(merged[due_unreported_filt & ((merged.has_protocol == 1) | (merged.has_sap == 1))])\n",
    "\n",
    "due_no_resuls_prot_sap = len(merged[due_unreported_filt & ((merged.has_protocol == 1) & (merged.has_sap == 1))])\n",
    "\n",
    "due_no_results_prot = len(merged[due_unreported_filt & ((merged.has_protocol == 1) & (merged.has_sap == 0))])\n",
    "\n",
    "due_no_results_sap = len(merged[due_unreported_filt & ((merged.has_protocol == 0) & (merged.has_sap == 1))])\n",
    "\n",
    "prot_after_comp = len(merged[due_reported_filt & (merged.has_protocol == 1) & (merged.prot_after_completion == 1)])\n",
    "\n",
    "sap_after_comp = len(merged[due_reported_filt & (merged.has_sap == 1) & (merged.sap_after_completion == 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'''\n",
    "{due_results} trials are due and have public results available (meaning they have completed QC review); \n",
    "{prot_and_sap} ({round(prot_and_sap/due_results * 100,1)}%) of these have a protocol and sap available. \n",
    "An additional {no_sap_statement} registered trials have a protocol available but the sponsor declared the \\\n",
    "study has no SAP in their trial record meaning {docs_accounted} ({round(docs_accounted/due_results * 100, 1)}%) \\\n",
    "trials have accounted for all required documentation. \n",
    "Among the {due_no_results} due trials without results available, \\\n",
    "{due_no_results_docs} ({round(due_no_results_docs/due_no_results*100,1)}%) have some form of documentation \\\n",
    "available: {due_no_resuls_prot_sap} have a protocol and SAP, {due_no_results_prot} have just a protocol, \\\n",
    "and {due_no_results_sap} has just a SAP.\n",
    "{prot_after_comp} ({round(prot_after_comp/docs_accounted * 100,1)}%) of the trials with a protocol and \\\n",
    "{sap_after_comp} ({round(sap_after_comp/len(merged[due_reported_filt & (merged.has_sap == 1)]) * 100,1)}%) of \\\n",
    "those with a SAP first submitted or updated these documents after trial completion.\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "just_due_results = merged[(merged.has_results == 1) & (merged.results_due == 1)].reset_index(drop=True)\n",
    "\n",
    "just_due_results['docs_accounted'] = np.where((just_due_results.has_protocol == 1) | \n",
    "                                              (just_due_results.has_sap == 1),1,0)\n",
    "\n",
    "x_docs = just_due_results[['act_flag', 'ind_spon', 'drug_trial', 'late_phase', 'N/A', 'quartile_2', \n",
    "                           'quartile_3', 'quartile_4']].reset_index(drop=True)\n",
    "y_docs = just_due_results.docs_accounted.reset_index(drop=True)\n",
    "\n",
    "conf = simple_logistic_regression(y_docs,x_docs, cis=.001)\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use this cell to check crude regression analysis of interest:\n",
    "\n",
    "crude_x = just_due_results[['quartile_2', 'quartile_3', 'quartile_4']].reset_index(drop=True)\n",
    "\n",
    "simple_logistic_regression(y_docs,crude_x,cis=.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_rank = create_ranking(just_due_results, 'docs_accounted', marker = 0)\n",
    "docs_rank_merge = docs_rank.merge(covered_trials, on='sponsor')\n",
    "docs_rank_merge['prct'] = round((docs_rank_merge['docs_accounted'] / docs_rank_merge['covered_trials']) * 100,2)\n",
    "docs_rank_merge[docs_rank_merge.covered_trials >= 50].sort_values(by='prct', ascending=False).head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "all",
   "notebook_metadata_filter": "all,-language_info",
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.5",
    "jupytext_version": "1.3.3"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
