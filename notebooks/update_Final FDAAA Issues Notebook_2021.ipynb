{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "from tqdm.auto import tqdm\n",
    "import seaborn as sns\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "cwd = os.getcwd()\n",
    "parent = str(Path(cwd).parents[0])\n",
    "sys.path.append(parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Managing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the processed data files exists (for covered and all trials), it will read it, if not it will create it from the raw data. See files in the `lib` folder and function docstrings for details of functions. The GitHub will always contains the processed data files but interested users should also be able to re-create them from the raw data as needed. The process used to archive the raw data in our storage format is detailed here:\n",
    "https://github.com/ebmdatalab/clinicaltrials-act-converter\n",
    "\n",
    "The processed data is included in this repository in the `data` folder. The raw data is too large to easily store on GitHub so we load it in from Dropbox storage when needed. If the Dropbox link ever fails, you can also download a copy of the raw data from here:\n",
    "https://doi.org/10.6084/m9.figshare.12789902\n",
    "\n",
    "You can then unzip and import/run `get_data_local` instead of `get_data` on the CSV locally to get the processed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv(parent + '/data/applicable_trials_2021-01-18.csv')\n",
    "    \n",
    "    #This file is zipped for easier storage on GitHub.\n",
    "    zip_file = ZipFile(parent + '/data/all_trials_2021-01-18.csv.zip')\n",
    "    df2 = pd.read_csv(zip_file.open('all_trials_2021-01-18.csv'))\n",
    "    del zip_file\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    old_fda = parent + '/data/fdaaa_regulatory_snapshot.csv'\n",
    "    \n",
    "    #This data is the full ClinicalTrials.gov dataset for 18 Jan 2021.\n",
    "    #Due to size, this is not in our GitHub repo, but stored on Dropbox \n",
    "    #You should also be able to download the raw data using this URL\n",
    "    path = 'https://www.dropbox.com/s/awlhqwjtkzp6t4b/clinicaltrials_raw_clincialtrials_json_2021-01-18.csv.zip?dl=1'\n",
    "\n",
    "    from lib.data_functions import fda_reg, get_data\n",
    "\n",
    "    fda_reg_dict = fda_reg(old_fda)\n",
    "    lines = get_data(path)\n",
    "\n",
    "    #headers is just the list of header names to save space here\n",
    "    from lib.final_df import make_row, make_dataframe, headers\n",
    "\n",
    "    #Just pACTs/ACTs\n",
    "    df = make_dataframe(tqdm(lines), fda_reg_dict, headers, act_filter=True, scrape_date = date(2021,1,18))\n",
    "    \n",
    "    #Everything on CT.gov\n",
    "    df2 = make_dataframe(tqdm(lines), fda_reg_dict, headers, act_filter=False, scrape_date = date(2021,1,18))\n",
    "    \n",
    "    #We won't need this anymore so deleting to save some memory\n",
    "    del lines\n",
    "    \n",
    "    #Uncomment this to save as a csv as appropriate\n",
    "    #df.to_csv(parent + '/data/applicable_trials_2021-01-18.csv', index=False)\n",
    "    #df2.to_csv(parent + '/data/all_trials_2021-01-18.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the sponsor size variable for regressions\n",
    "\n",
    "#Getting counts of each sponsor across all of ClinicalTrials.gov\n",
    "#Making a single column and dummies\n",
    "group = df2[['nct_id', 'sponsor']].groupby('sponsor', as_index = False).count()\n",
    "group.columns = ['sponsor', 'sponsored_trials']\n",
    "df = df.merge(group, how='left', on='sponsor')\n",
    "df['sponsor_quartile'] = pd.Categorical(pd.qcut(df.sponsored_trials, 4, labels=False), ordered=True)\n",
    "s_q_df = pd.get_dummies(df.sponsor_quartile, prefix='s_q')\n",
    "df = df.join(s_q_df)\n",
    "\n",
    "#renaming columns\n",
    "quart_rename = {'s_q_0': 'quartile_1', 's_q_1': 'quartile_2',  \n",
    "                's_q_2': 'quartile_3', 's_q_3': 'quartile_4'}\n",
    "df.rename(columns=quart_rename, inplace=True)\n",
    "\n",
    "#Checking the ranges\n",
    "quartile_ranges = pd.qcut(df.sponsored_trials, 4)\n",
    "print(quartile_ranges.unique())\n",
    "\n",
    "#creating a count of sponsors for applicable trials for rankings\n",
    "app_group = df[['nct_id', 'sponsor']].groupby('sponsor', as_index = False).count()\n",
    "app_group.columns = ['sponsor', 'covered_trials']\n",
    "df = df.merge(app_group, how='left', on='sponsor')\n",
    "\n",
    "#This is grouped by mean because each \"group\" of a single sponsor contains the same number of trials\n",
    "#Could easily just be .max() or .min() as well\n",
    "covered_trials = df[['sponsor', 'covered_trials']].groupby(by='sponsor', as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check that the quartiles assigned correctly\n",
    "df['sponsor_quartile'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating regression variables for use throughout\n",
    "df['ind_spon'] = np.where(df.sponsor_type == 'Industry', 1, 0)\n",
    "df['drug_trial'] = np.where(df.intervention_types.str.contains('Drug'), 1, 0)\n",
    "phase_cats = ['Phase 1/Phase 2', 'Phase 2', 'Phase 2/Phase 3', 'Phase 3', 'Phase 4', 'N/A']\n",
    "df.phase.fillna('N/A', inplace=True)\n",
    "df['phase_collapsed'] = np.where(df.phase.isin(phase_cats[0:2]), 'Early Phase', \n",
    "                                np.where(df.phase.isin(phase_cats[2:4]), 'Late Phase', \"N/A\"))\n",
    "df['phase_var'] = pd.Categorical(df.phase_collapsed, ordered=True, \n",
    "                                 categories = ['Early Phase', 'Late Phase', 'N/A'])\n",
    "df['phase_var'] = df['phase_var'].cat.codes.astype('category')\n",
    "phase_df = pd.get_dummies(df.phase_var, prefix = 'phase_cat')\n",
    "\n",
    "df = df.join(phase_df)\n",
    "\n",
    "phase_rename = {'phase_cat_0': 'early_phase', 'phase_cat_1': 'late_phase', 'phase_cat_2': 'N/A'}\n",
    "\n",
    "df.rename(columns=phase_rename, inplace=True)\n",
    "\n",
    "#Making sure date columns are dates\n",
    "date_cols = ['certificate_date', \"certificate_date_qc\", \"certificate_posted_date\", 'primary_completion_date', 'completion_date', \n",
    "             'available_completion_date', 'due_date', 'last_updated_date', 'last_verified_date', 'results_first_submitted_date', \n",
    "             'results_submitted_date_qc', 'results_first_posted_date',  'first_results_submission_any', \n",
    "             'study_first_submitted_date', 'study_submitted_date_qc', 'study_first_posted_date', 'start_date']\n",
    "\n",
    "for col in date_cols:\n",
    "    df[col] = pd.to_datetime(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_cols = ['act_flag', 'ind_spon', 'drug_trial', 'early_phase', 'late_phase', 'N/A', \n",
    "                 'quartile_1', 'quartile_2', 'quartile_3', 'quartile_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing functions created for analysis\n",
    "from lib.analysis_functions import crosstab, simple_logistic_regression, create_ranking, get_count, get_prcts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall Cohort Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Describing full data\n",
    "total = len(df2)\n",
    "all_applicable = len(df)\n",
    "acts = df.act_flag.sum()\n",
    "pacts = df.included_pact_flag.sum()\n",
    "results_due = df.results_due.sum()\n",
    "due_reported = len(df[(((df.has_results == 1) | (df.pending_results == 1)) & (df.results_due == 1))])\n",
    "results_all = df.has_results.sum() + df.pending_results.sum()\n",
    "df['reported_late'] = np.where(((df.results_due == 1) & (df.due_date < df.first_results_submission_any) & \n",
    "                                df.first_results_submission_any.notnull()), 1, 0)\n",
    "df['compliant_reported'] = np.where((df.results_due == 1) & (df.reported_late == 0) & ((df.has_results == 1) | (df.pending_results == 1)), 1, 0)\n",
    "late_results = df.reported_late.sum()\n",
    "\n",
    "\n",
    "print(\n",
    "    f'''As of 18 January 2021, there are {total} trials and\n",
    "{all_applicable} publicly identifiable applicable trials covered by the law.\n",
    "{acts} ({round(acts/all_applicable * 100,1)}%) of these are identifiable as ACTs \n",
    "and {pacts} ({round(pacts/all_applicable * 100,1)}%) as pACTs.\n",
    "{results_due} ({round(results_due/all_applicable * 100 ,1)}%) are due to report results.\n",
    "{results_all} ({round(results_all/all_applicable * 100 ,1)}%) of the entire cohort \n",
    "and {due_reported} ({round(due_reported/results_due * 100 ,1)}%) of the due cohort have any results submitted.\n",
    "{due_reported - late_results} ({round(((due_reported - late_results)/results_due) * 100, 1)}%) of the due trials submitted their results on time.    \n",
    "    '''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this function to get reporting compliance crosstabs for any variable of interest \n",
    "crosstab(df[df.results_due == 1], 'compliant_reported', 'act_flag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Values for Table 1\n",
    "\n",
    "summary = {}\n",
    "\n",
    "for a in analysis_cols:\n",
    "    cross = crosstab(df[df.results_due == 1], 'compliant_reported', a)\n",
    "    summary[a] = get_prcts(cross)\n",
    "    \n",
    "pd.DataFrame(summary).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use this function to get the counts of values for any variable in the dataset\n",
    "#Can use this on any study population throughout the analysis\n",
    "\n",
    "#Example\n",
    "get_count(df, 'sponsor_quartile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Note:** \n",
    "\n",
    "**The below analyses contain some additional descriptive data for each area (e.g., additional figures, sponsor-level compliance information) not included in the published work due to space limits of the format. This remains in the notebook for any interested parties and to support N. DeVito's doctoral thesis which may draw on this data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Registration - Prospective and >21 Days Late"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FDAAA 2007 requires that all covered trials are registered within 21 days of their start date, that is the date in which the first participant is enrolled in the study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the fields we need\n",
    "pr_cats = ['nct_id', 'act_flag', 'included_pact_flag', 'start_date', 'study_first_submitted_date', \n",
    "           'study_submitted_date_qc', 'study_first_posted_date', 'available_completion_date', 'sponsor', \n",
    "           'ind_spon', 'drug_trial', 'phase_var', 'early_phase', 'late_phase', 'N/A', 'quartile_1', 'quartile_2', \n",
    "           'quartile_3', 'quartile_4']\n",
    "\n",
    "pr_df = df[pr_cats].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this accounts for when the reg requirement came fully into effect as of Sept 27, 2008\n",
    "pr_df['start_date_mod'] = np.where(pr_df.start_date < pd.Timestamp(2008,9,27), pd.Timestamp(2008,9,27) - pd.DateOffset(days=21),\n",
    "                                   pr_df.start_date.dt.date)\n",
    "\n",
    "#filter to check for trials registered within 21 days of the start date\n",
    "legal_check = pr_df.study_first_submitted_date > (pr_df.start_date_mod + pd.DateOffset(days=21))\n",
    "#1 means it was registered within the legal limit, 0 means in violation\n",
    "pr_df['legal_reg'] = np.where(legal_check, 0, 1)\n",
    "\n",
    "#filter to check for registration before the start date\n",
    "pros_check = pr_df.study_first_submitted_date > pr_df.start_date\n",
    "#1 means prospectively registered, 0 means retrospectively\n",
    "pr_df['pros_reg'] = np.where(pros_check, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{} trials out of {} ({}%) covered trials were registered on time the legal definition'.format(\n",
    "    len(pr_df[pr_df.legal_reg == 1]), len(pr_df), round(len(pr_df[pr_df.legal_reg == 1])/len(pr_df) * 100,2)))\n",
    "\n",
    "print('{} trials out of {} ({}%) covered trials were registered prospectively'.format(\n",
    "    len(pr_df[pr_df.pros_reg == 1]), len(pr_df), round(len(pr_df[pr_df.pros_reg == 1])/len(pr_df) * 100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating days late to register by the legal standard\n",
    "\n",
    "legally_late = pr_df[pr_df.legal_reg == 0].reset_index(drop=True)\n",
    "legally_late['days_late'] = (legally_late.study_first_submitted_date - (legally_late.start_date_mod + pd.DateOffset(days=21))) / pd.Timedelta('1 day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting legal registration status by ACT/pACT status\n",
    "act_late = crosstab(pr_df, 'legal_reg','act_flag')\n",
    "act_late"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Percent of ACTs and pACTs registered late\n",
    "late_pacts = round((act_late.iloc[0, :][0] / (act_late.iloc[0, :][0] + act_late.iloc[0, :][1])) * 100,1)\n",
    "print(f\"{late_pacts}% of pACTs were registered late\")\n",
    "\n",
    "late_acts = round((act_late.iloc[1, :][0] / (act_late.iloc[1, :][0] + act_late.iloc[1, :][1])) * 100,1)\n",
    "print(f\"{late_acts}% of ACTs were registered late\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descriptive statistics for days late\n",
    "legally_late['days_late'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_bins = np.arange(0,1100 + 1, 100)\n",
    "xlabels = ['0', '100', '200', '300', '400', '500', '600', '700', '800', '900', '1000+']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 15), dpi=300)\n",
    "ax.set_axisbelow(True)\n",
    "ax.grid(zorder=0)\n",
    "sns.distplot(np.clip(legally_late['days_late'],0,1000), hist=True, kde=False, bins=reg_bins, ax=ax,\n",
    "             hist_kws = {'zorder':10}).set(xlim=(0,1100))\n",
    "plt.xticks(reg_bins)\n",
    "ax.set_xticklabels(xlabels)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.tick_params(axis='both', which='major', labelsize=20)\n",
    "plt.ylabel('# of Trials', fontsize=25, labelpad=10)\n",
    "plt.xlabel('Days Late', fontsize=25, labelpad=10)\n",
    "plt.title(\"a. Days Registered Beyond the 21 Day Legal Limit\", pad = 20, fontsize = 30)\n",
    "plt.show()\n",
    "#plt.savefig('figures/late_registration_1a.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can use this function to get crosstabs for covariate of interest\n",
    "crosstab(pr_df, 'legal_reg','act_flag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Values for Table 1\n",
    "\n",
    "summary = {}\n",
    "\n",
    "for a in analysis_cols:\n",
    "    cross = crosstab(pr_df, 'legal_reg', a)\n",
    "    summary[a] = get_prcts(cross)\n",
    "    \n",
    "pd.DataFrame(summary).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_reg = pr_df[['act_flag', 'ind_spon', 'drug_trial', 'late_phase', 'N/A', \n",
    "               'quartile_2', 'quartile_3', 'quartile_4']].reset_index(drop=True)\n",
    "y_reg = pr_df['legal_reg'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use this cell to check crude regression analysis of interest:\n",
    "\n",
    "crude_x = pr_df[['quartile_2', 'quartile_3', 'quartile_4']].reset_index(drop=True)\n",
    "\n",
    "simple_logistic_regression(y_reg,crude_x,cis=.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adjusted model for legal registration\n",
    "\n",
    "conf = simple_logistic_regression(y_reg,x_reg,cis=.001)\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we are measuring late registrations so set the \"legal_reg\" markerer to 0\n",
    "\n",
    "reg_rank = create_ranking(pr_df, 'legal_reg', marker=0)\n",
    "#r_top_10_prct = reg_rank.legal_reg.quantile(.95)\n",
    "reg_rank_merge = reg_rank.merge(covered_trials, on='sponsor')\n",
    "reg_rank_merge['prct'] = round((reg_rank_merge['legal_reg'] / reg_rank_merge['covered_trials']) * 100,2)\n",
    "\n",
    "#Check beyond top 10 to make sure no ties\n",
    "reg_rank_merge[reg_rank_merge.covered_trials >= 50].sort_values(by='prct', ascending=False).head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_by_year = pr_df[['study_first_submitted_date', 'legal_reg']].groupby(pr_df.study_first_submitted_date.dt.year).agg(['sum', 'count'])\n",
    "\n",
    "comp_by_year['prct_comp'] = round((comp_by_year['legal_reg']['sum'] / comp_by_year['legal_reg']['count']) * 100,2)\n",
    "\n",
    "reg_trends = comp_by_year[(comp_by_year.index >= 2009) & (comp_by_year.index <= 2020)]['prct_comp']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5), dpi=300)\n",
    "plt.plot(reg_trends, marker='o')\n",
    "plt.xticks(reg_trends.index)\n",
    "plt.yticks(range(0,101,10))\n",
    "plt.grid()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.ylabel('% FDAAA Compliant', fontsize=12, labelpad=5)\n",
    "plt.xlabel('Registration Year', fontsize=12, labelpad=7)\n",
    "plt.title(\"Compliant Registrations by Year Registered\", pad = 20, fontsize = 15)\n",
    "plt.show()\n",
    "#plt.savefig('figures/reg_trends.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Last Verified Date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Final Rule states that all covered trials are required to verify their data once a year. Here we examine how many trials, registered for more than a year, had verified within the last calendar year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['nct_id', 'has_results', 'pending_results', 'primary_completion_date', 'completion_date', 'study_first_posted_date', \n",
    "        'last_verified_date', 'last_updated_date', 'sponsor', 'act_flag', 'ind_spon', 'drug_trial', 'phase_var', \n",
    "        'early_phase', 'late_phase', 'N/A', 'quartile_1', 'quartile_2', 'quartile_3', 'quartile_4']\n",
    "update_dataset = df[cols].reset_index(drop=True)\n",
    "\n",
    "update_dataset['scrape_date'] = date(2021,1,18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logic for exclusion\n",
    "print('We start with all applicable trials: {}'.format(len(df)))\n",
    "\n",
    "#We exclude trials that were first posted to ClinicalTrials.gov within the last year \n",
    "#as they don't have a full year of follow-up\n",
    "exclude_under_a_year = update_dataset.study_first_posted_date >= pd.Timestamp(2020,1,18)\n",
    "print(\"Exclude {} for starting within the last year (since 18 Jan 2020)\".format(len(update_dataset[exclude_under_a_year])))\n",
    "new_excluded = update_dataset[~exclude_under_a_year].reset_index(drop=True)\n",
    "print(\"{} remaining\".format(len(new_excluded)))\n",
    "\n",
    "#We then exclude trials that have reached full completion as of the scrape date and have posted results.\n",
    "#The law frees you from your responsibility to verify once a year when you have posted all results following\n",
    "#completion of the trial\n",
    "complete_results = (new_excluded.completion_date < new_excluded.scrape_date) & (new_excluded.has_results == 1)\n",
    "print(\"Exclude {} for being completed with public results\".format(len(new_excluded[complete_results])))\n",
    "complete_excluded = new_excluded[~complete_results].reset_index(drop=True)\n",
    "print(\"{} remaining\".format(len(complete_excluded)))\n",
    "\n",
    "#Lastly we exclude trials with pending results as these likely have a newer verification that will appear once the\n",
    "#results complete QC review.\n",
    "print(\"Eclude {} for being currently pending\".format(len(complete_excluded[complete_excluded.pending_results==1])))\n",
    "cohort = complete_excluded[complete_excluded.pending_results == 0].reset_index(drop=True)\n",
    "print(\"{} remaining\".format(len(cohort)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dummy for late verification\n",
    "#Our data is from 18 Jan 2021 meaning verifications older than 18 January 2020 are officially out of date. \n",
    "#However, verifications are usually only provided in \"Month Year\" format with no date. As such, they are defaulted\n",
    "#to the beginning of the month. Conservatively, we will treat 1 January 2019 as our cutoff.\n",
    "\n",
    "# Late Verification = 0, Currently Verified = 1\n",
    "cohort['comp_veri'] = np.where(cohort.last_verified_date >= pd.Timestamp(2020,1,1), 1,0)\n",
    "cohort['late_veri'] = np.where(cohort.last_verified_date < pd.Timestamp(2020,1,1), 1,0)\n",
    "late_veri = len(cohort[cohort.comp_veri == 0])\n",
    "prct_late = round(cohort.late_veri.sum()/len(cohort)*100,1)\n",
    "print('{} of {} ({}%) of eligible trials are overdue to verify their records'.format(len(cohort)-late_veri, len(cohort), 100-prct_late))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#describing the days late for unverified trials\n",
    "\n",
    "cohort['verification_due'] = cohort.last_verified_date + pd.DateOffset(years=1)\n",
    "cohort['days_late'] = np.where(cohort.comp_veri == 0, (pd.Timestamp(2021,1,1) - cohort.verification_due) / pd.Timedelta('1 day'), 0)\n",
    "cohort[cohort['comp_veri'] == 0].days_late.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "late_with_update = len(cohort[(cohort.comp_veri == 0) & (cohort.last_updated_date > pd.Timestamp(2020,1,18))])\n",
    "\n",
    "print('{} trials with a late verification updated since 1 January 2019'.format(late_with_update))\n",
    "print('This is {}% of the currently late trials'.format(round(late_with_update/late_veri * 100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ver_bins = np.arange(0,1100 + 1, 100)\n",
    "xlabels = ['0', '100', '200', '300', '400', '500', '600', '700', '800', '900', '1000+']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 15), dpi=300)\n",
    "ax.set_axisbelow(True)\n",
    "ax.grid(zorder=0)\n",
    "sns.distplot(np.clip(cohort[cohort['comp_veri'] == 0].days_late,0,1000), hist=True, kde=False, bins=ver_bins, ax=ax,\n",
    "             hist_kws = {'zorder':10}).set(xlim=(0,1100))\n",
    "plt.xticks(ver_bins)\n",
    "ax.set_xticklabels(xlabels)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.tick_params(axis='both', which='major', labelsize=20)\n",
    "plt.ylabel('# of Trials', fontsize=25, labelpad=10)\n",
    "plt.xlabel('Days Late', fontsize=25, labelpad=10)\n",
    "plt.title(\"b. Days Late to Verify Trial Data\", pad = 20, fontsize = 30)\n",
    "plt.show()\n",
    "#plt.savefig('figures/last_verified_1b.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can crosstab any variable here.\n",
    "crosstab(cohort, 'comp_veri', 'act_flag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Table 1\n",
    "summary = {}\n",
    "\n",
    "for a in analysis_cols:\n",
    "    cross = crosstab(cohort, 'comp_veri', a)\n",
    "    summary[a] = get_prcts(cross)\n",
    "    \n",
    "pd.DataFrame(summary).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_veri = cohort.comp_veri\n",
    "x_veri = cohort[['act_flag', 'ind_spon', 'drug_trial', 'late_phase', 'N/A', 'quartile_2', \n",
    "                 'quartile_3', 'quartile_4']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use this cell for crude OR of interest by changeing the value of crude_x\n",
    "\n",
    "crude_x = cohort[['late_phase', 'N/A']].reset_index(drop=True)\n",
    "\n",
    "simple_logistic_regression(y_veri,crude_x,cis=.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outcome here is having a current verification date - adjusted\n",
    "\n",
    "simple_logistic_regression(y_veri,x_veri, cis=.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veri_rank = create_ranking(cohort, 'late_veri')\n",
    "#v_top_10_prct = veri_rank.late_veri.quantile(.95)\n",
    "veri_rank_merge = veri_rank.merge(covered_trials, on='sponsor')\n",
    "veri_rank_merge['prct'] = round((veri_rank_merge['late_veri'] / veri_rank_merge['covered_trials']) * 100,2)\n",
    "\n",
    "veri_rank_merge[veri_rank_merge.covered_trials >= 50].sort_values(by='prct', ascending=False).head(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Certificate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sponsors of trials covered under FDAAA can seek delays to the deadline to seek results under certain circumstances. The Final Rule specified that these certificates must be requested prior to when the results would otherwise become does (i.e., a year from primary completion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cert_analysis = df[['nct_id','due_date', 'has_results', 'has_certificate', \"certificate_date_qc\", \"certificate_posted_date\",\n",
    "                    'certificate_date', 'late_cert', 'results_submitted_date_qc', 'sponsor', 'act_flag', 'ind_spon', 'drug_trial', \n",
    "                    'phase_var', 'early_phase', 'late_phase', 'N/A', 'quartile_1', 'quartile_2', 'quartile_3', \n",
    "                    'quartile_4']].reset_index(drop=True)\n",
    "\n",
    "#all_trials = df[['nct_id', 'due_date', 'results_due', 'has_certificate']].reset_index(drop=True)\n",
    "#all_trials['due_date'] = pd.to_datetime(all_trials.due_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "certificate = cert_analysis[cert_analysis.has_certificate == 1].reset_index(drop=True)\n",
    "all_certificates = certificate.nct_id.count()\n",
    "late_certificates = certificate.late_cert.sum()\n",
    "certificate['on_time_cert'] = np.where(certificate.late_cert==1, 0, 1)\n",
    "certs_with_results = certificate.has_results[certificate.has_results == 1].sum()\n",
    "late_certs_with_results = certificate.has_results[(certificate.has_results == 1) & (certificate.late_cert == 1)].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('As of 18 Jan 2021, {} ({}%) trials had recieved Certificates of Delay out of {} applicable trials'\n",
    "      .format(all_certificates, round(all_certificates/len(df) * 100, 2), len(df)))\n",
    "print('{} of those {} ({}%) have results'\n",
    "      .format(certs_with_results, all_certificates, round(certs_with_results/all_certificates * 100,2)))\n",
    "print('{} of certificates were submitted late. That is {}% of all certificates'\n",
    "      .format(late_certificates, round((late_certificates/all_certificates)*100)))\n",
    "print('Of those submitted late, only {} have since posted any results, {}% of all late certificates'\n",
    "      .format(late_certs_with_results, round(late_certs_with_results/late_certificates * 100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#certificate['due_date'] = pd.to_datetime(certificate.due_date)\n",
    "#certificate['certificate_date'] = pd.to_datetime(certificate.certificate_date)\n",
    "#certificate['results_submitted_date_qc'] = pd.to_datetime(certificate.results_submitted_date_qc)\n",
    "certificate['scrape_date'] = pd.Timestamp(2021,1,18)\n",
    "certificate['days_late'] = certificate.certificate_date - certificate.due_date\n",
    "days_late_count = certificate.days_late[certificate.late_cert == 1] / pd.Timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_late_count.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{len(days_late_count[days_late_count > 100])} of {len(days_late_count)} trials with a \\\n",
    "late certificate were more than 100 days late to apply. That is \\\n",
    "{round((len(days_late_count[days_late_count > 100])/len(days_late_count))*100,1)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_bins = np.arange(0,450 + 1, 50)\n",
    "xlabels = ['0', '50', '100', '150', '200', '250', '300', '350', '400+']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 15), dpi=300)\n",
    "ax.set_axisbelow(True)\n",
    "ax.grid(zorder=0)\n",
    "sns.distplot(np.clip(days_late_count,0,400), hist=True, kde=False, bins=lc_bins, ax=ax,\n",
    "             hist_kws = {'zorder':10}).set(xlim=(0,450))\n",
    "ax.set_xticklabels(xlabels)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.tick_params(axis='both', which='major', labelsize=20)\n",
    "plt.ylabel('# of Trials', fontsize=25, labelpad=10)\n",
    "plt.xlabel('Days Late', fontsize=25, labelpad=10)\n",
    "plt.title(\"c. Days Late to Apply for Certificate of Delay\", pad = 20, fontsize = 30)\n",
    "plt.show()\n",
    "#plt.savefig('figures/late_certificate_1c.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can crosstab any variable here\n",
    "crosstab(certificate, 'on_time_cert', 'act_flag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Table 1\n",
    "summary = {}\n",
    "\n",
    "for a in analysis_cols:\n",
    "    cross = crosstab(certificate, 'on_time_cert', a)\n",
    "    summary[a] = get_prcts(cross)\n",
    "    \n",
    "pd.DataFrame(summary).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cert = certificate[['act_flag', 'ind_spon', 'drug_trial', 'late_phase', 'N/A', 'quartile_2', 'quartile_3', \n",
    "                      'quartile_4']].reset_index(drop=True)\n",
    "y_cert = certificate['on_time_cert'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use this cell to check crude regression analysis of interest:\n",
    "\n",
    "crude_x = certificate[['quartile_2', 'quartile_3', 'quartile_4']].reset_index(drop=True)\n",
    "\n",
    "simple_logistic_regression(y_cert,crude_x,cis=.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outcome here is having an on-time certificate\n",
    "\n",
    "simple_logistic_regression(y_cert,x_cert, cis=.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cert_rank = create_ranking(certificate, 'late_cert')\n",
    "#c_top_10_prct = cert_rank.late_cert.quantile(.95)\n",
    "cert_rank_merge = cert_rank.merge(covered_trials, on='sponsor')\n",
    "cert_rank_merge['prct'] = round((cert_rank_merge['late_cert'] / cert_rank_merge['covered_trials']) * 100,2)\n",
    "cert_rank_merge[cert_rank_merge.covered_trials >= 50].sort_values(by='prct', ascending=False).reset_index(drop=True).head(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Final Rule stipulates that a protocol and statistical analysis plan for covered trials are required to be reported alongside results for trials covered under the FDAAA 2007."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_df = df[['nct_id', 'results_due', 'has_results', 'pending_results', 'has_certificate','results_first_submitted_date', \n",
    "             'results_first_posted_date','primary_completion_date', 'due_date', 'last_updated_date', 'documents', 'sponsor',\n",
    "             'act_flag','ind_spon', 'drug_trial', 'phase_var', 'early_phase', 'late_phase', 'N/A', 'quartile_1', \n",
    "             'quartile_2', 'quartile_3', 'quartile_4']].reset_index(drop=True)\n",
    "\n",
    "doc_df['has_documents'] = np.where(doc_df.documents.notnull(), 1,0)\n",
    "doc_df['results_first_submitted_date'] = pd.to_datetime(doc_df['results_first_submitted_date'])\n",
    "doc_df['primary_completion_date'] = pd.to_datetime(doc_df['primary_completion_date'])\n",
    "doc_df['due_date'] = pd.to_datetime(doc_df['due_date'])\n",
    "doc_df['last_updated_date'] = pd.to_datetime(doc_df['last_updated_date'])\n",
    "doc_df['results_first_posted_date'] = pd.to_datetime(doc_df['results_first_posted_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Describing the population\n",
    "\n",
    "due_and_docs = len(doc_df[(doc_df.results_due == 1) & (doc_df.has_documents == 1)])\n",
    "due_docs_reported = len(doc_df[(doc_df.results_due == 1) & (doc_df.has_documents == 1) & (doc_df.has_results == 1)])\n",
    "results_no_docs = len(doc_df[(doc_df.results_due == 1) & (doc_df.has_documents == 0) & (doc_df.has_results == 1)])\n",
    "no_results_docs = len(doc_df[(doc_df.results_due == 1) & (doc_df.has_documents == 1) & (doc_df.has_results == 0) ])\n",
    "check = len(doc_df[(doc_df.results_due == 1) & (doc_df.has_documents == 0) & (doc_df.has_results == 0) & (doc_df.pending_results==1)])\n",
    "results_due = doc_df.results_due.sum()\n",
    "print('{} Trials are due to report results, and therefore should have uploaded a protocol and SAP'.format(results_due))\n",
    "print('Of these {} due trials have any documents, {} due trials have both documents and results'.format(due_and_docs,due_docs_reported))\n",
    "print('{} due trials have documents but no results, {} have no documents but results'.format(no_results_docs, results_no_docs))\n",
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_docs_df = doc_df[['nct_id', 'documents']][doc_df.has_documents == 1].reset_index(drop=True)\n",
    "\n",
    "has_docs_ids = has_docs_df.nct_id.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this makes each document it's own row with nct_id as the index\n",
    "dfs_list = []\n",
    "\n",
    "import ast\n",
    "has_docs = has_docs_df.copy()\n",
    "has_docs['documents'] = has_docs['documents'].apply(ast.literal_eval)\n",
    "for index, row in has_docs.iterrows():\n",
    "    if isinstance(has_docs['documents'][index], list):\n",
    "        l = len(has_docs['documents'][index])\n",
    "        ix = [has_docs['nct_id'][index]] * l\n",
    "        interim_df = pd.DataFrame(has_docs['documents'][index], index = ix)\n",
    "        dfs_list.append(interim_df)\n",
    "    else:\n",
    "        interim_df = pd.DataFrame(has_docs['documents'][index], index = [has_docs['nct_id'][index]])\n",
    "        dfs_list.append(interim_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Further processing\n",
    "nct_index_df = pd.concat(dfs_list, sort=True)\n",
    "nct_index_df = nct_index_df.reset_index(level=0)\n",
    "nct_index_df.rename(columns= {nct_index_df.columns[0]: \"nct_id\"}, inplace=True)\n",
    "\n",
    "#fixing incorrect data points that came up in summary review of data\n",
    "#(verfified in document https://clinicaltrials.gov/ProvidedDocs/10/NCT01866410/Prot_SAP_000.pdf)\n",
    "#(and in document https://clinicaltrials.gov/ProvidedDocs/42/NCT03241342/Prot_SAP_000.pdf)\n",
    "bad_index = nct_index_df.index[nct_index_df['document_date'] == 'January 24, 1014'].tolist()[0]\n",
    "nct_index_df.at[bad_index,'document_date'] = 'January 24, 2014'\n",
    "bad_index = nct_index_df.index[nct_index_df['document_date'] == 'April 10, 1018'].tolist()[0]\n",
    "nct_index_df.at[bad_index,'document_date'] = 'April 10, 2018'\n",
    "\n",
    "nct_index_df['document_date'] = pd.to_datetime(nct_index_df['document_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The first time you run this notebook on a new dataset, you can get the data on when the documents \n",
    "#were last updated by importing and running the \"history_scrape\" function. However, if you are using \n",
    "#the shared data from the project or re-running a prior analysis you can just export and save a CSV that \n",
    "#you can then re-load.\n",
    "\n",
    "#If you already have the output from the above exported to CSV, just run this cell pointing to that file\n",
    "#if it isn't already in the same directory (this will work assuming no changed to the cloned repo)\n",
    "\n",
    "try:\n",
    "    docs_updates = pd.read_csv(parent + '/data/history_scrape_2021-01-18.csv')\n",
    "except FileNotFoundError:\n",
    "    from lib.trial_history import history_scrape\n",
    "    most_recent_doc_update = history_scrape(tqdm(has_docs_ids[820:]), date(2021,1,18))\n",
    "    docs_updates = pd.DataFrame(most_recent_doc_update)\n",
    "    docs_updates.to_csv('history_scrape_{}.csv'.format(date(2021,1,18)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning and managing the scraped data as above\n",
    "bad_index = docs_updates.index[docs_updates['document_date'] == 'January 24, 1014'].tolist()[0]\n",
    "docs_updates.at[bad_index,'document_date'] = 'January 24, 2014'\n",
    "bad_index = docs_updates.index[docs_updates['document_date'] == 'April 10, 1018'].tolist()[0]\n",
    "docs_updates.at[bad_index,'document_date'] = 'April 10, 2018'\n",
    "docs_updates['upload_date'] = pd.to_datetime(docs_updates['upload_date'])\n",
    "docs_updates['document_date'] = pd.to_datetime(docs_updates['document_date'])\n",
    "docs_updates['version_date'] = pd.to_datetime(docs_updates['version_date'])\n",
    "docs_updates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For ease of analysis we set dummy dates, for submission dates not scraped, \n",
    "#either very far in the past or future. This makes determining the earliest and latest\n",
    "#submission dates much easier during grouping in the next step\n",
    "full_docs_df = nct_index_df.merge(docs_updates, on=['nct_id', 'document_date', 'document_type'])\n",
    "full_docs_df['dummy_date_past'] = pd.to_datetime(-2208988800, unit='s')\n",
    "full_docs_df['dummy_date_future'] = pd.to_datetime(4102444800, unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting to 1 line per trial\n",
    "\n",
    "def f(x):\n",
    "    d = {}\n",
    "    d['number_of_documents'] = x.nct_id.count()\n",
    "    d['num_protocol_docs'] = np.where(x.document_has_protocol == 'Yes',1,0).sum()\n",
    "    d['num_sap_docs'] = np.where(x.document_has_sap == 'Yes',1,0).sum()\n",
    "    d['has_protocol'] = np.where(((np.where(x.document_has_protocol == 'Yes',1,0).sum())>0),1,0)\n",
    "    d['has_sap'] = np.where(((np.where(x.document_has_sap == 'Yes',1,0).sum())>0),1,0)\n",
    "    d['no_sap'] = np.where((np.where(x.no_sap.notnull(), 1, 0).sum() > 0), 1, 0)\n",
    "    d['first_protocol_submitted'] = np.where(x.document_has_protocol == 'Yes', x.upload_date,x.dummy_date_future).min()\n",
    "    d['latest_protocol_submitted'] = np.where(x.document_has_protocol == 'Yes', x.upload_date,x.dummy_date_past).max()\n",
    "    d['first_sap_submitted'] = np.where(x.document_has_sap == 'Yes', x.upload_date,x.dummy_date_future).min()\n",
    "    d['latest_sap_submitted'] = np.where(x.document_has_sap == 'Yes', x.upload_date,x.dummy_date_past).max()\n",
    "    return pd.Series(d)\n",
    "\n",
    "grouped = full_docs_df.groupby('nct_id').apply(f).reset_index()\n",
    "\n",
    "#Now we can easily replace those far in the future/past dates with nulls\n",
    "grouped.loc[grouped['latest_protocol_submitted'] == '1900-01-01', 'latest_protocol_submitted'] = pd.NaT\n",
    "grouped.loc[grouped['latest_sap_submitted'] == '1900-01-01', 'latest_sap_submitted'] = pd.NaT\n",
    "grouped.loc[grouped['first_protocol_submitted'] == '2100-01-01', 'first_protocol_submitted'] = pd.NaT\n",
    "grouped.loc[grouped['first_sap_submitted'] == '2100-01-01', 'first_sap_submitted'] = pd.NaT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bringing in additional data we need for further analysis\n",
    "\n",
    "more_cols = ['nct_id', 'results_due', 'has_results', 'pending_results', 'primary_completion_date', 'due_date', \n",
    "             'results_first_submitted_date', 'results_first_posted_date', 'last_updated_date', 'ind_spon', 'drug_trial', \n",
    "             'phase_var', 'sponsor', 'act_flag', 'early_phase', 'late_phase', 'N/A', 'quartile_1', 'quartile_2', 'quartile_3', \n",
    "             'quartile_4']\n",
    "merged = doc_df[more_cols].merge(grouped, how='left', on='nct_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data cleaning\n",
    "merged.number_of_documents.fillna(0, inplace=True)\n",
    "merged.num_protocol_docs.fillna(0, inplace=True)\n",
    "merged.num_sap_docs.fillna(0, inplace=True)\n",
    "merged.has_protocol.fillna(0, inplace=True)\n",
    "merged.has_sap.fillna(0, inplace=True)\n",
    "merged.no_sap.fillna(0, inplace=True)\n",
    "merged['prot_after_completion'] = np.where(merged.latest_protocol_submitted > merged.primary_completion_date, 1, 0)\n",
    "merged['sap_after_completion'] = np.where(merged.latest_sap_submitted > merged.primary_completion_date, 1, 0)\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filters\n",
    "\n",
    "due_reported_filt = ((merged.results_due == 1) & (merged.has_results == 1))\n",
    "\n",
    "due_unreported_filt = (merged.results_due == 1) & (merged.has_results == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building various counts to describe the population below\n",
    "\n",
    "#The number due to report results\n",
    "all_due = len(merged[(merged.results_due == 1)])\n",
    "\n",
    "#The number of these that have results\n",
    "due_results = len(merged[due_reported_filt])\n",
    "\n",
    "#Pending results should have results eventually (but we can't assess right now)\n",
    "pending = len(merged[due_unreported_filt & (merged.pending_results == 1)])\n",
    "\n",
    "#Due, results fully available, and has a protocol and a SAP\n",
    "prot_and_sap = len(merged[due_reported_filt & (merged.has_protocol == 1) & (merged.has_sap == 1)])\n",
    "\n",
    "#Due, results fully available, and has a protocol, a SAP, or a proactive statement that no SAP exists\n",
    "prot_sap_or_no_sap_stmt = len(merged[due_reported_filt & (merged.has_protocol == 1) \n",
    "                                     & ((merged.has_sap == 1) | (merged.no_sap == 1))])\n",
    "\n",
    "#Due, results, prot, sap unaccounted\n",
    "prot_unaccounted_sap = len(merged[due_reported_filt & (merged.has_protocol == 1) \n",
    "                                     & ((merged.has_sap == 0) & (merged.no_sap == 0))])\n",
    "\n",
    "#Due, results, sap accounted, no prot\n",
    "sap_unaccounted_prot = len(merged[due_reported_filt & (merged.has_protocol == 0) \n",
    "                                     & ((merged.has_sap == 1) | (merged.no_sap == 1))])\n",
    "\n",
    "\n",
    "#total due and unreported\n",
    "due_unreported = len(merged[due_unreported_filt])\n",
    "\n",
    "#No results, but has some form of documents available/accounted for\n",
    "unreported_any_docs = len(merged[due_unreported_filt & ((merged.has_protocol == 1) | ((merged.has_sap == 1) | (merged.no_sap == 1)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'''There are {due_results} trials that are due to report and have subsequently completed clinicaltrials.gov \\\n",
    "quality control meaning results are fully posted. Of these, \\\n",
    "{prot_and_sap} ({round((prot_and_sap/due_results) * 100, 2)}%) have their protocol and sap included in their record. \\\n",
    "An additional {prot_sap_or_no_sap_stmt-prot_and_sap} trials have proactively declared they have no SAP meaning \\\n",
    "{prot_sap_or_no_sap_stmt} ({round((prot_sap_or_no_sap_stmt/due_results) * 100, 2)}%) have all documents and results \\\n",
    "fully accounted for. \\\n",
    "Among trials without results, {unreported_any_docs} ({round((unreported_any_docs/due_unreported)* 100, 2)}%) have \\\n",
    "any form of documentation available. \\\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "just_due_results = merged[(merged.has_results == 1) & (merged.results_due == 1)].reset_index(drop=True)\n",
    "\n",
    "just_due_results['docs_accounted'] = np.where((just_due_results.has_protocol == 1) & \n",
    "                                              ((just_due_results.has_sap == 1) | \n",
    "                                               (just_due_results.no_sap == 1)),1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstab(just_due_results, 'docs_accounted', 'act_flag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Table 1\n",
    "summary = {}\n",
    "\n",
    "for a in analysis_cols:\n",
    "    cross = crosstab(just_due_results, 'docs_accounted', a)\n",
    "    summary[a] = get_prcts(cross)\n",
    "    \n",
    "pd.DataFrame(summary).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The regression doesn't converge with 'act_flag' included as it is perfectly predictive, so this is removed\n",
    "x_docs = just_due_results[['ind_spon', 'drug_trial', 'late_phase', 'N/A', 'quartile_2', \n",
    "                           'quartile_3', 'quartile_4']].reset_index(drop=True)\n",
    "y_docs = just_due_results.docs_accounted.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use this cell to check crude regression analysis of interest:\n",
    "\n",
    "crude_x = just_due_results[['quartile_2', 'quartile_3', 'quartile_4']].reset_index(drop=True)\n",
    "\n",
    "simple_logistic_regression(y_docs,crude_x,cis=.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adjusted regression\n",
    "\n",
    "simple_logistic_regression(y_docs,x_docs, cis=.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_rank = create_ranking(just_due_results, 'docs_accounted', marker = 0)\n",
    "docs_rank_merge = docs_rank.merge(covered_trials, on='sponsor')\n",
    "docs_rank_merge['prct'] = round((docs_rank_merge['docs_accounted'] / docs_rank_merge['covered_trials']) * 100,2)\n",
    "docs_rank_merge[docs_rank_merge.covered_trials >= 50].sort_values(by='prct', ascending=False).head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "all",
   "notebook_metadata_filter": "all,-language_info",
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.5",
    "jupytext_version": "1.3.3"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
